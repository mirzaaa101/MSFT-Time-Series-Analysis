{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3be39c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-04-01</th>\n",
       "      <td>40.60</td>\n",
       "      <td>40.76</td>\n",
       "      <td>40.31</td>\n",
       "      <td>40.72</td>\n",
       "      <td>36865322.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-02</th>\n",
       "      <td>40.66</td>\n",
       "      <td>40.74</td>\n",
       "      <td>40.12</td>\n",
       "      <td>40.29</td>\n",
       "      <td>37487476.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-06</th>\n",
       "      <td>40.34</td>\n",
       "      <td>41.78</td>\n",
       "      <td>40.18</td>\n",
       "      <td>41.55</td>\n",
       "      <td>39223692.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-07</th>\n",
       "      <td>41.61</td>\n",
       "      <td>41.91</td>\n",
       "      <td>41.31</td>\n",
       "      <td>41.53</td>\n",
       "      <td>28809375.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-08</th>\n",
       "      <td>41.48</td>\n",
       "      <td>41.69</td>\n",
       "      <td>41.04</td>\n",
       "      <td>41.42</td>\n",
       "      <td>24753438.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Open   High    Low  Close      Volume\n",
       "Date                                              \n",
       "2015-04-01  40.60  40.76  40.31  40.72  36865322.0\n",
       "2015-04-02  40.66  40.74  40.12  40.29  37487476.0\n",
       "2015-04-06  40.34  41.78  40.18  41.55  39223692.0\n",
       "2015-04-07  41.61  41.91  41.31  41.53  28809375.0\n",
       "2015-04-08  41.48  41.69  41.04  41.42  24753438.0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/Microsoft_Stock.csv\", parse_dates=[\"Date\"])\n",
    "\n",
    "df['Date'] = df['Date'].dt.date # Extract only the date part\n",
    "df['Volume'] = df['Volume'].astype(float)\n",
    "\n",
    "df.drop_duplicates(inplace=True)\n",
    "df = df.sort_values(\"Date\").set_index(\"Date\")\n",
    "df.index = pd.to_datetime(df.index)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92305f3d",
   "metadata": {},
   "source": [
    "#### Naive Forecating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "372626a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Forecast MAE = 11078096.830452127\n"
     ]
    }
   ],
   "source": [
    "diff_7 = df['Volume'].diff(7)[\"2015-04\":]\n",
    "naive_mae = diff_7.abs().mean()\n",
    "print(f\"Naive Forecast MAE = {naive_mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ead8833",
   "metadata": {},
   "source": [
    "#### The ARMA Model Family: SARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b4aada7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "36d372ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "origin, start_date, end_date = \"2016-01-01\", \"2016-04-01\", \"2021-03-31\"\n",
    "time_period = pd.date_range(start_date, end_date)\n",
    "\n",
    "volume_series = df.loc[origin:end_date][\"Volume\"].asfreq(\"D\")\n",
    "y_preds = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f5fbc4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SARIMA Forecast MAE = 6909895.069312916\n"
     ]
    }
   ],
   "source": [
    "for today in time_period.shift(-1):\n",
    "    model = ARIMA(volume_series[origin:today], order=(1, 0, 0), seasonal_order=(0, 1, 1, 7))\n",
    "    model = model.fit()\n",
    "    y_pred = model.forecast()[0]\n",
    "    y_preds.append(y_pred)\n",
    "\n",
    "y_preds = pd.Series(y_preds, index=time_period)\n",
    "sarima_mae = (y_preds - volume_series[time_period]).abs().mean()\n",
    "print(f\"SARIMA Forecast MAE = {sarima_mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0bfbc4",
   "metadata": {},
   "source": [
    "#### Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ba083f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_train = df[\"Volume\"][:\"2019-12\"]/1e6\n",
    "volume_valid = df[\"Volume\"][\"2020-01\":\"2020-08\"]/1e6\n",
    "volume_test = df[\"Volume\"][\"2020-09\":\"2021-03\"]/1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "39b2e4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "seq_length = 56\n",
    "\n",
    "train_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    volume_train.to_numpy(),\n",
    "    targets=volume_train[seq_length:],\n",
    "    sequence_length=seq_length,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "valid_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    volume_valid.to_numpy(),\n",
    "    targets=volume_valid[seq_length:],\n",
    "    sequence_length=seq_length,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "456e15fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_evaluate(model, train_set, valid_set, learning_rate, epochs=500):\n",
    "    early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor=\"val_mae\", patience=50, restore_best_weights=True)\n",
    "    opt = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9)\n",
    "    model.compile(loss=tf.keras.losses.Huber(), optimizer=opt, metrics=[\"mae\"])\n",
    "    history = model.fit(train_set, validation_data=valid_set, epochs=epochs, callbacks=[early_stopping_cb])\n",
    "    valid_loss, valid_mae = model.evaluate(valid_set)\n",
    "    return valid_mae * 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e3afc183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "36/36 [==============================] - 1s 9ms/step - loss: 247.4206 - mae: 247.9202 - val_loss: 367.3449 - val_mae: 367.8449\n",
      "Epoch 2/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 208.7112 - mae: 209.2112 - val_loss: 543.7933 - val_mae: 544.2933\n",
      "Epoch 3/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 392.7336 - mae: 393.2335 - val_loss: 832.2133 - val_mae: 832.7133\n",
      "Epoch 4/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 484.6264 - mae: 485.1262 - val_loss: 767.6802 - val_mae: 768.1802\n",
      "Epoch 5/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 279.5536 - mae: 280.0536 - val_loss: 320.4626 - val_mae: 320.9626\n",
      "Epoch 6/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 170.3143 - mae: 170.8143 - val_loss: 220.1760 - val_mae: 220.6760\n",
      "Epoch 7/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 206.9194 - mae: 207.4188 - val_loss: 671.0414 - val_mae: 671.5414\n",
      "Epoch 8/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 329.1944 - mae: 329.6938 - val_loss: 1691.0248 - val_mae: 1691.5248\n",
      "Epoch 9/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 426.1758 - mae: 426.6758 - val_loss: 827.8502 - val_mae: 828.3502\n",
      "Epoch 10/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 262.2804 - mae: 262.7804 - val_loss: 470.5964 - val_mae: 471.0964\n",
      "Epoch 11/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 227.3621 - mae: 227.8613 - val_loss: 649.8968 - val_mae: 650.3968\n",
      "Epoch 12/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 435.0918 - mae: 435.5914 - val_loss: 1120.2980 - val_mae: 1120.7980\n",
      "Epoch 13/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 292.7080 - mae: 293.2080 - val_loss: 373.8023 - val_mae: 374.3023\n",
      "Epoch 14/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 181.4339 - mae: 181.9330 - val_loss: 269.6822 - val_mae: 270.1822\n",
      "Epoch 15/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 249.6392 - mae: 250.1390 - val_loss: 357.4130 - val_mae: 357.9130\n",
      "Epoch 16/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 289.3759 - mae: 289.8755 - val_loss: 1420.0973 - val_mae: 1420.5973\n",
      "Epoch 17/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 691.9266 - mae: 692.4265 - val_loss: 107.6118 - val_mae: 108.1118\n",
      "Epoch 18/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 248.3816 - mae: 248.8803 - val_loss: 511.4100 - val_mae: 511.9100\n",
      "Epoch 19/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 219.3335 - mae: 219.8326 - val_loss: 393.6478 - val_mae: 394.1478\n",
      "Epoch 20/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 227.8394 - mae: 228.3394 - val_loss: 365.3592 - val_mae: 365.8592\n",
      "Epoch 21/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 244.1268 - mae: 244.6268 - val_loss: 315.7765 - val_mae: 316.2765\n",
      "Epoch 22/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 318.2722 - mae: 318.7718 - val_loss: 250.7323 - val_mae: 251.2302\n",
      "Epoch 23/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 209.2570 - mae: 209.7566 - val_loss: 302.9520 - val_mae: 303.4520\n",
      "Epoch 24/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 359.9366 - mae: 360.4366 - val_loss: 530.8568 - val_mae: 531.3568\n",
      "Epoch 25/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 278.6185 - mae: 279.1185 - val_loss: 410.1178 - val_mae: 410.6178\n",
      "Epoch 26/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 230.5936 - mae: 231.0934 - val_loss: 499.2219 - val_mae: 499.7219\n",
      "Epoch 27/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 351.3591 - mae: 351.8588 - val_loss: 122.0422 - val_mae: 122.5422\n",
      "Epoch 28/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 336.9771 - mae: 337.4765 - val_loss: 128.7661 - val_mae: 129.2661\n",
      "Epoch 29/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 215.0354 - mae: 215.5352 - val_loss: 343.3295 - val_mae: 343.8295\n",
      "Epoch 30/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 309.0744 - mae: 309.5740 - val_loss: 187.1678 - val_mae: 187.6678\n",
      "Epoch 31/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 607.8326 - mae: 608.3325 - val_loss: 1187.6051 - val_mae: 1188.1051\n",
      "Epoch 32/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 380.6387 - mae: 381.1384 - val_loss: 429.0511 - val_mae: 429.5511\n",
      "Epoch 33/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 290.5847 - mae: 291.0840 - val_loss: 67.7841 - val_mae: 68.2841\n",
      "Epoch 34/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 147.0242 - mae: 147.5231 - val_loss: 202.6653 - val_mae: 203.1653\n",
      "Epoch 35/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 241.4458 - mae: 241.9458 - val_loss: 793.5225 - val_mae: 794.0225\n",
      "Epoch 36/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 601.4517 - mae: 601.9517 - val_loss: 393.9518 - val_mae: 394.4518\n",
      "Epoch 37/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 391.2101 - mae: 391.7098 - val_loss: 606.2550 - val_mae: 606.7550\n",
      "Epoch 38/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 373.0693 - mae: 373.5684 - val_loss: 62.8639 - val_mae: 63.3606\n",
      "Epoch 39/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 210.3708 - mae: 210.8702 - val_loss: 1039.3125 - val_mae: 1039.8125\n",
      "Epoch 40/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 379.5733 - mae: 380.0730 - val_loss: 1004.5949 - val_mae: 1005.0949\n",
      "Epoch 41/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 399.0719 - mae: 399.5716 - val_loss: 144.1123 - val_mae: 144.6123\n",
      "Epoch 42/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 346.3257 - mae: 346.8252 - val_loss: 1062.7793 - val_mae: 1063.2793\n",
      "Epoch 43/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 429.1858 - mae: 429.6858 - val_loss: 1124.3766 - val_mae: 1124.8766\n",
      "Epoch 44/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 331.4052 - mae: 331.9052 - val_loss: 193.4521 - val_mae: 193.9521\n",
      "Epoch 45/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 223.1751 - mae: 223.6745 - val_loss: 371.5567 - val_mae: 372.0567\n",
      "Epoch 46/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 240.0836 - mae: 240.5836 - val_loss: 334.9771 - val_mae: 335.4771\n",
      "Epoch 47/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 216.9850 - mae: 217.4850 - val_loss: 280.6481 - val_mae: 281.1481\n",
      "Epoch 48/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 160.7918 - mae: 161.2915 - val_loss: 225.6628 - val_mae: 226.1628\n",
      "Epoch 49/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 266.5839 - mae: 267.0830 - val_loss: 329.9599 - val_mae: 330.4599\n",
      "Epoch 50/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 336.0514 - mae: 336.5510 - val_loss: 613.3834 - val_mae: 613.8834\n",
      "Epoch 51/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 544.2274 - mae: 544.7274 - val_loss: 1401.6023 - val_mae: 1402.1023\n",
      "Epoch 52/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 656.4233 - mae: 656.9232 - val_loss: 506.9254 - val_mae: 507.4254\n",
      "Epoch 53/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 233.9376 - mae: 234.4372 - val_loss: 575.8320 - val_mae: 576.3320\n",
      "Epoch 54/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 422.9526 - mae: 423.4526 - val_loss: 910.7803 - val_mae: 911.2803\n",
      "Epoch 55/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 418.5271 - mae: 419.0271 - val_loss: 713.2811 - val_mae: 713.7811\n",
      "Epoch 56/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 267.6062 - mae: 268.1060 - val_loss: 756.6063 - val_mae: 757.1063\n",
      "Epoch 57/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 224.8408 - mae: 225.3404 - val_loss: 111.4031 - val_mae: 111.9024\n",
      "Epoch 58/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 630.4556 - mae: 630.9556 - val_loss: 1201.1447 - val_mae: 1201.6447\n",
      "Epoch 59/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 5ms/step - loss: 309.1724 - mae: 309.6722 - val_loss: 793.2524 - val_mae: 793.7524\n",
      "Epoch 60/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 340.9221 - mae: 341.4221 - val_loss: 443.3049 - val_mae: 443.8049\n",
      "Epoch 61/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 164.8972 - mae: 165.3955 - val_loss: 96.6223 - val_mae: 97.1223\n",
      "Epoch 62/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 374.5682 - mae: 375.0677 - val_loss: 645.6813 - val_mae: 646.1813\n",
      "Epoch 63/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 251.9788 - mae: 252.4782 - val_loss: 544.4774 - val_mae: 544.9774\n",
      "Epoch 64/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 284.8122 - mae: 285.3121 - val_loss: 961.6253 - val_mae: 962.1253\n",
      "Epoch 65/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 442.3506 - mae: 442.8506 - val_loss: 615.9493 - val_mae: 616.4493\n",
      "Epoch 66/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 233.1636 - mae: 233.6632 - val_loss: 789.3071 - val_mae: 789.8071\n",
      "Epoch 67/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 429.0235 - mae: 429.5235 - val_loss: 1086.9541 - val_mae: 1087.4541\n",
      "Epoch 68/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 430.4525 - mae: 430.9525 - val_loss: 921.2856 - val_mae: 921.7856\n",
      "Epoch 69/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 267.2322 - mae: 267.7317 - val_loss: 386.1177 - val_mae: 386.6177\n",
      "Epoch 70/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 242.9709 - mae: 243.4704 - val_loss: 856.0575 - val_mae: 856.5575\n",
      "Epoch 71/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 310.5795 - mae: 311.0795 - val_loss: 494.8996 - val_mae: 495.3996\n",
      "Epoch 72/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 196.3897 - mae: 196.8895 - val_loss: 148.3981 - val_mae: 148.8955\n",
      "Epoch 73/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 235.2199 - mae: 235.7194 - val_loss: 1377.8434 - val_mae: 1378.3434\n",
      "Epoch 74/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 490.2726 - mae: 490.7725 - val_loss: 782.8584 - val_mae: 783.3584\n",
      "Epoch 75/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 360.3491 - mae: 360.8489 - val_loss: 202.3503 - val_mae: 202.8502\n",
      "Epoch 76/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 438.9298 - mae: 439.4298 - val_loss: 827.8843 - val_mae: 828.3843\n",
      "Epoch 77/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 245.0868 - mae: 245.5868 - val_loss: 385.4084 - val_mae: 385.9084\n",
      "Epoch 78/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 196.2425 - mae: 196.7420 - val_loss: 403.6109 - val_mae: 404.1109\n",
      "Epoch 79/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 228.8907 - mae: 229.3902 - val_loss: 688.9847 - val_mae: 689.4847\n",
      "Epoch 80/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 291.3150 - mae: 291.8150 - val_loss: 701.7734 - val_mae: 702.2734\n",
      "Epoch 81/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 421.8940 - mae: 422.3935 - val_loss: 1042.5549 - val_mae: 1043.0549\n",
      "Epoch 82/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 334.0941 - mae: 334.5936 - val_loss: 342.8026 - val_mae: 343.3026\n",
      "Epoch 83/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 109.3109 - mae: 109.8100 - val_loss: 298.8932 - val_mae: 299.3932\n",
      "Epoch 84/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 512.7959 - mae: 513.2952 - val_loss: 459.4324 - val_mae: 459.9324\n",
      "Epoch 85/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 425.7126 - mae: 426.2126 - val_loss: 617.2588 - val_mae: 617.7588\n",
      "Epoch 86/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 458.9801 - mae: 459.4801 - val_loss: 490.2509 - val_mae: 490.7509\n",
      "Epoch 87/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 395.7820 - mae: 396.2814 - val_loss: 596.5323 - val_mae: 597.0323\n",
      "Epoch 88/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 201.5935 - mae: 202.0925 - val_loss: 88.6228 - val_mae: 89.1228\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 62.8639 - mae: 63.3606\n",
      "Linear Model Forecast MAE = 63360607.1472168\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "lin_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1, input_shape=[seq_length])\n",
    "])\n",
    "\n",
    "linear_mae = fit_and_evaluate(lin_model, train_ds, valid_ds, learning_rate=0.01)\n",
    "print(f\"Linear Model Forecast MAE = {linear_mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbf7914",
   "metadata": {},
   "source": [
    "#### Simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "dfb21c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "36/36 [==============================] - 2s 17ms/step - loss: 28.7940 - mae: 29.2940 - val_loss: 39.0985 - val_mae: 39.5985\n",
      "Epoch 2/500\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 28.7940 - mae: 29.2940 - val_loss: 39.0985 - val_mae: 39.5985\n",
      "Epoch 3/500\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 28.7940 - mae: 29.2940 - val_loss: 39.0985 - val_mae: 39.5985\n",
      "Epoch 4/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 28.7940 - mae: 29.2940 - val_loss: 39.0985 - val_mae: 39.5985\n",
      "Epoch 5/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 28.7940 - mae: 29.2940 - val_loss: 39.0985 - val_mae: 39.5985\n",
      "Epoch 6/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 28.7940 - mae: 29.2940 - val_loss: 39.0985 - val_mae: 39.5985\n",
      "Epoch 7/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 28.7940 - mae: 29.2940 - val_loss: 39.0985 - val_mae: 39.5985\n",
      "Epoch 8/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 28.7940 - mae: 29.2940 - val_loss: 39.0985 - val_mae: 39.5985\n",
      "Epoch 9/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 28.7940 - mae: 29.2940 - val_loss: 39.0985 - val_mae: 39.5985\n",
      "Epoch 10/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 28.7940 - mae: 29.2940 - val_loss: 39.0985 - val_mae: 39.5985\n",
      "Epoch 11/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 28.7940 - mae: 29.2940 - val_loss: 39.0985 - val_mae: 39.5985\n",
      "Epoch 12/500\n",
      "36/36 [==============================] - 1s 13ms/step - loss: 28.7940 - mae: 29.2940 - val_loss: 39.0985 - val_mae: 39.5985\n",
      "Epoch 13/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 28.7940 - mae: 29.2940 - val_loss: 39.0985 - val_mae: 39.5985\n",
      "Epoch 14/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 28.7940 - mae: 29.2940 - val_loss: 39.0985 - val_mae: 39.5985\n",
      "Epoch 15/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 28.7940 - mae: 29.2940 - val_loss: 39.0985 - val_mae: 39.5985\n",
      "Epoch 16/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 28.7940 - mae: 29.2940 - val_loss: 39.0985 - val_mae: 39.5985\n",
      "Epoch 17/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 28.7940 - mae: 29.2940 - val_loss: 39.0985 - val_mae: 39.5985\n",
      "Epoch 18/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 28.7940 - mae: 29.2940 - val_loss: 39.0985 - val_mae: 39.5985\n",
      "Epoch 19/500\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 28.7940 - mae: 29.2940 - val_loss: 39.0985 - val_mae: 39.5985\n",
      "Epoch 20/500\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 28.7940 - mae: 29.2940 - val_loss: 39.0985 - val_mae: 39.5985\n",
      "Epoch 21/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 28.7940 - mae: 29.2940 - val_loss: 39.0985 - val_mae: 39.5985\n",
      "Epoch 22/500\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 28.7940 - mae: 29.2940 - val_loss: 39.0985 - val_mae: 39.5985\n",
      "Epoch 23/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 28.7940 - mae: 29.2940 - val_loss: 39.0985 - val_mae: 39.5985\n",
      "Epoch 24/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 28.7940 - mae: 29.2940 - val_loss: 39.0985 - val_mae: 39.5985\n",
      "Epoch 25/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 28.7940 - mae: 29.2940 - val_loss: 39.0985 - val_mae: 39.5985\n",
      "Epoch 26/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 28.7940 - mae: 29.2940 - val_loss: 39.0985 - val_mae: 39.5985\n",
      "Epoch 27/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 28.7939 - mae: 29.2939 - val_loss: 39.0985 - val_mae: 39.5985\n",
      "Epoch 28/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 28.7940 - mae: 29.2940 - val_loss: 39.0985 - val_mae: 39.5985\n",
      "Epoch 29/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 28.7940 - mae: 29.2940 - val_loss: 39.0985 - val_mae: 39.5985\n",
      "Epoch 30/500\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 28.7940 - mae: 29.2940 - val_loss: 39.0985 - val_mae: 39.5985\n",
      "Epoch 31/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 28.7939 - mae: 29.2939 - val_loss: 39.0985 - val_mae: 39.5985\n",
      "Epoch 32/500\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 28.7939 - mae: 29.2939 - val_loss: 39.0985 - val_mae: 39.5985\n",
      "Epoch 33/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 28.7939 - mae: 29.2939 - val_loss: 39.0985 - val_mae: 39.5985\n",
      "Epoch 34/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 28.7939 - mae: 29.2939 - val_loss: 39.0985 - val_mae: 39.5985\n",
      "Epoch 35/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 28.7939 - mae: 29.2939 - val_loss: 39.0985 - val_mae: 39.5985\n",
      "Epoch 36/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 28.7939 - mae: 29.2939 - val_loss: 39.0985 - val_mae: 39.5985\n",
      "Epoch 37/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 28.7939 - mae: 29.2939 - val_loss: 39.0985 - val_mae: 39.5985\n",
      "Epoch 38/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 28.7939 - mae: 29.2939 - val_loss: 39.0985 - val_mae: 39.5985\n",
      "Epoch 39/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 28.7939 - mae: 29.2939 - val_loss: 39.0985 - val_mae: 39.5985\n",
      "Epoch 40/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 28.7939 - mae: 29.2939 - val_loss: 39.0985 - val_mae: 39.5985\n",
      "Epoch 41/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 28.7939 - mae: 29.2939 - val_loss: 39.0985 - val_mae: 39.5985\n",
      "Epoch 42/500\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 28.7939 - mae: 29.2939 - val_loss: 39.0985 - val_mae: 39.5985\n",
      "Epoch 43/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 28.7939 - mae: 29.2939 - val_loss: 39.0985 - val_mae: 39.5985\n",
      "Epoch 44/500\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 28.7939 - mae: 29.2939 - val_loss: 39.0985 - val_mae: 39.5985\n",
      "Epoch 45/500\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 28.7939 - mae: 29.2939 - val_loss: 39.0985 - val_mae: 39.5985\n",
      "Epoch 46/500\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 28.7939 - mae: 29.2939 - val_loss: 39.0985 - val_mae: 39.5985\n",
      "Epoch 47/500\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 28.7939 - mae: 29.2939 - val_loss: 39.0985 - val_mae: 39.5985\n",
      "Epoch 48/500\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 28.7939 - mae: 29.2939 - val_loss: 39.0985 - val_mae: 39.5985\n",
      "Epoch 49/500\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 28.7939 - mae: 29.2939 - val_loss: 39.0985 - val_mae: 39.5985\n",
      "Epoch 50/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 28.7939 - mae: 29.2939 - val_loss: 39.0985 - val_mae: 39.5985\n",
      "Epoch 51/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 28.7939 - mae: 29.2939 - val_loss: 39.0985 - val_mae: 39.5985\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 39.0985 - mae: 39.5985\n",
      "Simple RNN Model Forecast MAE = 39598537.44506836\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "simple_rnn_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(1, input_shape=[None,1])\n",
    "])\n",
    "simple_rnn_mae = fit_and_evaluate(simple_rnn_model, train_ds, valid_ds, learning_rate=0.01)\n",
    "print(f\"Simple RNN Model Forecast MAE = {simple_rnn_mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e640831",
   "metadata": {},
   "source": [
    "#### Deep RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "51ff53d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "36/36 [==============================] - 4s 42ms/step - loss: 13.9459 - mae: 14.4379 - val_loss: 12.7977 - val_mae: 13.2864\n",
      "Epoch 2/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 8.0544 - mae: 8.5385 - val_loss: 13.8750 - val_mae: 14.3718\n",
      "Epoch 3/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 8.0046 - mae: 8.4907 - val_loss: 13.3505 - val_mae: 13.8412\n",
      "Epoch 4/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 8.0086 - mae: 8.4954 - val_loss: 13.7858 - val_mae: 14.2812\n",
      "Epoch 5/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 7.9865 - mae: 8.4667 - val_loss: 13.6674 - val_mae: 14.1605\n",
      "Epoch 6/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 7.9962 - mae: 8.4803 - val_loss: 13.5003 - val_mae: 13.9927\n",
      "Epoch 7/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 8.0552 - mae: 8.5400 - val_loss: 14.1187 - val_mae: 14.6178\n",
      "Epoch 8/500\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 7.9861 - mae: 8.4707 - val_loss: 13.8973 - val_mae: 14.3945\n",
      "Epoch 9/500\n",
      "36/36 [==============================] - 1s 35ms/step - loss: 7.9938 - mae: 8.4789 - val_loss: 13.8782 - val_mae: 14.3751\n",
      "Epoch 10/500\n",
      "36/36 [==============================] - 1s 36ms/step - loss: 8.0191 - mae: 8.5044 - val_loss: 13.7630 - val_mae: 14.2581\n",
      "Epoch 11/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 8.0389 - mae: 8.5258 - val_loss: 13.7745 - val_mae: 14.2700\n",
      "Epoch 12/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 7.9945 - mae: 8.4786 - val_loss: 13.8827 - val_mae: 14.3805\n",
      "Epoch 13/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 7.8761 - mae: 8.3608 - val_loss: 12.8762 - val_mae: 13.3633\n",
      "Epoch 14/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 7.8330 - mae: 8.3147 - val_loss: 11.5968 - val_mae: 12.0818\n",
      "Epoch 15/500\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 8.0317 - mae: 8.5190 - val_loss: 13.5902 - val_mae: 14.0832\n",
      "Epoch 16/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 7.9824 - mae: 8.4688 - val_loss: 14.6483 - val_mae: 15.1474\n",
      "Epoch 17/500\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 8.0291 - mae: 8.5142 - val_loss: 13.8864 - val_mae: 14.3833\n",
      "Epoch 18/500\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 8.0077 - mae: 8.4906 - val_loss: 13.9622 - val_mae: 14.4600\n",
      "Epoch 19/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 7.9987 - mae: 8.4821 - val_loss: 13.8077 - val_mae: 14.3035\n",
      "Epoch 20/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 7.9840 - mae: 8.4707 - val_loss: 14.1328 - val_mae: 14.6320\n",
      "Epoch 21/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 7.9801 - mae: 8.4613 - val_loss: 13.5708 - val_mae: 14.0637\n",
      "Epoch 22/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 8.0211 - mae: 8.5067 - val_loss: 14.3458 - val_mae: 14.8457\n",
      "Epoch 23/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 8.0080 - mae: 8.4897 - val_loss: 13.9903 - val_mae: 14.4885\n",
      "Epoch 24/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 8.0239 - mae: 8.5063 - val_loss: 14.3504 - val_mae: 14.8503\n",
      "Epoch 25/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.9544 - mae: 8.4378 - val_loss: 13.3117 - val_mae: 13.8017\n",
      "Epoch 26/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.9546 - mae: 8.4376 - val_loss: 14.7716 - val_mae: 15.2691\n",
      "Epoch 27/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 7.8958 - mae: 8.3798 - val_loss: 14.3539 - val_mae: 14.8538\n",
      "Epoch 28/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.9807 - mae: 8.4639 - val_loss: 14.1119 - val_mae: 14.6117\n",
      "Epoch 29/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 7.9851 - mae: 8.4708 - val_loss: 14.0159 - val_mae: 14.5142\n",
      "Epoch 30/500\n",
      "36/36 [==============================] - 1s 34ms/step - loss: 8.0698 - mae: 8.5542 - val_loss: 14.9959 - val_mae: 15.4898\n",
      "Epoch 31/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 7.9938 - mae: 8.4781 - val_loss: 13.9040 - val_mae: 14.4014\n",
      "Epoch 32/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.9931 - mae: 8.4779 - val_loss: 13.6950 - val_mae: 14.1887\n",
      "Epoch 33/500\n",
      "36/36 [==============================] - 1s 34ms/step - loss: 7.9799 - mae: 8.4658 - val_loss: 13.6864 - val_mae: 14.1798\n",
      "Epoch 34/500\n",
      "36/36 [==============================] - 1s 35ms/step - loss: 8.0290 - mae: 8.5145 - val_loss: 14.3649 - val_mae: 14.8648\n",
      "Epoch 35/500\n",
      "36/36 [==============================] - 1s 34ms/step - loss: 7.9940 - mae: 8.4784 - val_loss: 13.6547 - val_mae: 14.1478\n",
      "Epoch 36/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.9614 - mae: 8.4493 - val_loss: 13.8856 - val_mae: 14.3826\n",
      "Epoch 37/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 7.9832 - mae: 8.4699 - val_loss: 14.4497 - val_mae: 14.9496\n",
      "Epoch 38/500\n",
      "36/36 [==============================] - 1s 34ms/step - loss: 7.9878 - mae: 8.4740 - val_loss: 13.9544 - val_mae: 14.4522\n",
      "Epoch 39/500\n",
      "36/36 [==============================] - 1s 34ms/step - loss: 7.9807 - mae: 8.4644 - val_loss: 14.2603 - val_mae: 14.7600\n",
      "Epoch 40/500\n",
      "36/36 [==============================] - 1s 36ms/step - loss: 7.9873 - mae: 8.4719 - val_loss: 13.7202 - val_mae: 14.2143\n",
      "Epoch 41/500\n",
      "36/36 [==============================] - 1s 34ms/step - loss: 7.9741 - mae: 8.4589 - val_loss: 13.7325 - val_mae: 14.2268\n",
      "Epoch 42/500\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 7.9771 - mae: 8.4651 - val_loss: 13.5271 - val_mae: 14.0197\n",
      "Epoch 43/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 7.9815 - mae: 8.4704 - val_loss: 14.0161 - val_mae: 14.5145\n",
      "Epoch 44/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 7.9658 - mae: 8.4502 - val_loss: 13.7326 - val_mae: 14.2270\n",
      "Epoch 45/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 7.9919 - mae: 8.4745 - val_loss: 13.9960 - val_mae: 14.4941\n",
      "Epoch 46/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.9953 - mae: 8.4779 - val_loss: 13.6840 - val_mae: 14.1774\n",
      "Epoch 47/500\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 7.9753 - mae: 8.4584 - val_loss: 13.6569 - val_mae: 14.1501\n",
      "Epoch 48/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.9732 - mae: 8.4553 - val_loss: 13.4012 - val_mae: 13.8924\n",
      "Epoch 49/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 7.9661 - mae: 8.4538 - val_loss: 13.5658 - val_mae: 14.0587\n",
      "Epoch 50/500\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 7.9995 - mae: 8.4861 - val_loss: 13.9518 - val_mae: 14.4495\n",
      "Epoch 51/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 8.0173 - mae: 8.5008 - val_loss: 14.2283 - val_mae: 14.7278\n",
      "Epoch 52/500\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 7.9921 - mae: 8.4778 - val_loss: 14.0048 - val_mae: 14.5031\n",
      "Epoch 53/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.9955 - mae: 8.4845 - val_loss: 13.9749 - val_mae: 14.4729\n",
      "Epoch 54/500\n",
      "36/36 [==============================] - 1s 34ms/step - loss: 7.9840 - mae: 8.4667 - val_loss: 13.5883 - val_mae: 14.0813\n",
      "Epoch 55/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 8.0150 - mae: 8.4994 - val_loss: 14.0598 - val_mae: 14.5585\n",
      "Epoch 56/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.9738 - mae: 8.4589 - val_loss: 13.8283 - val_mae: 14.3244\n",
      "Epoch 57/500\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 7.9823 - mae: 8.4649 - val_loss: 14.0917 - val_mae: 14.5906\n",
      "Epoch 58/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 7.9837 - mae: 8.4723 - val_loss: 13.7406 - val_mae: 14.2352\n",
      "Epoch 59/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 7.9731 - mae: 8.4603 - val_loss: 13.5582 - val_mae: 14.0510\n",
      "Epoch 60/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.9796 - mae: 8.4665 - val_loss: 13.7184 - val_mae: 14.2125\n",
      "Epoch 61/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.9967 - mae: 8.4818 - val_loss: 14.5112 - val_mae: 15.0110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 8.1275 - mae: 8.6126 - val_loss: 13.9386 - val_mae: 14.4362\n",
      "Epoch 63/500\n",
      "36/36 [==============================] - 1s 36ms/step - loss: 7.9980 - mae: 8.4835 - val_loss: 14.1350 - val_mae: 14.6342\n",
      "Epoch 64/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 7.9817 - mae: 8.4655 - val_loss: 13.7460 - val_mae: 14.2406\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 11.5968 - mae: 12.0818\n",
      "Deep RNN Model Forecast MAE = 12081774.711608887\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "deep_rnn_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(32, return_sequences=True, input_shape=[None,1]),\n",
    "    tf.keras.layers.SimpleRNN(32, return_sequences=True),\n",
    "    tf.keras.layers.SimpleRNN(32),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "deep_rnn_mae = fit_and_evaluate(deep_rnn_model, train_ds, valid_ds, learning_rate=0.01)\n",
    "print(f\"Deep RNN Model Forecast MAE = {deep_rnn_mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b8d7aa",
   "metadata": {},
   "source": [
    "#### Sequence to Sequence Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5f8dd5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_windows(dataset, window_size):\n",
    "    dataset = dataset.window(window_size, shift=1, drop_remainder=True)\n",
    "    dataset = dataset.flat_map(lambda window: window.batch(window_size))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d7bad5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_seq2seq_dataset(series, seq_length=56, ahead=14, target_col=1, batch_size=32, shuffle=False, seed=None):\n",
    "    ds = to_windows(tf.data.Dataset.from_tensor_slices(series), ahead + 1)\n",
    "    ds = to_windows(ds, seq_length).map(lambda S: (S[:, :-ahead], S[:, -ahead:]))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(8 * batch_size, seed=seed)\n",
    "    return ds.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f59f31d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq_train = to_seq2seq_dataset(volume_train, shuffle=True, seed=42)\n",
    "seq2seq_valid = to_seq2seq_dataset(volume_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3cbba210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "36/36 [==============================] - 2s 23ms/step - loss: 25.5894 - mae: 26.0894 - val_loss: 38.3677 - val_mae: 38.8677\n",
      "Epoch 2/500\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 17.7970 - mae: 18.2952 - val_loss: 30.0377 - val_mae: 30.5376\n",
      "Epoch 3/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 10.9214 - mae: 11.4093 - val_loss: 23.4980 - val_mae: 23.9953\n",
      "Epoch 4/500\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 8.4336 - mae: 8.9154 - val_loss: 20.8730 - val_mae: 21.3716\n",
      "Epoch 5/500\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 8.0761 - mae: 8.5618 - val_loss: 20.0908 - val_mae: 20.5879\n",
      "Epoch 6/500\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 8.0259 - mae: 8.5134 - val_loss: 19.8648 - val_mae: 20.3616\n",
      "Epoch 7/500\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 8.0181 - mae: 8.5054 - val_loss: 19.7425 - val_mae: 20.2392\n",
      "Epoch 8/500\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 8.0120 - mae: 8.4992 - val_loss: 19.7226 - val_mae: 20.2192\n",
      "Epoch 9/500\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 8.0033 - mae: 8.4905 - val_loss: 19.8175 - val_mae: 20.3140\n",
      "Epoch 10/500\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 7.9892 - mae: 8.4732 - val_loss: 20.5205 - val_mae: 21.0192\n",
      "Epoch 11/500\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 8.0524 - mae: 8.5388 - val_loss: 20.0198 - val_mae: 20.5169\n",
      "Epoch 12/500\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 7.9944 - mae: 8.4806 - val_loss: 21.2773 - val_mae: 21.7728\n",
      "Epoch 13/500\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 8.0461 - mae: 8.5322 - val_loss: 19.5449 - val_mae: 20.0407\n",
      "Epoch 14/500\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 7.9813 - mae: 8.4649 - val_loss: 20.6140 - val_mae: 21.1127\n",
      "Epoch 15/500\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 8.0263 - mae: 8.5108 - val_loss: 19.8951 - val_mae: 20.3917\n",
      "Epoch 16/500\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 8.0247 - mae: 8.5115 - val_loss: 19.7126 - val_mae: 20.2091\n",
      "Epoch 17/500\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 8.0003 - mae: 8.4838 - val_loss: 20.7088 - val_mae: 21.2075\n",
      "Epoch 18/500\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 8.0666 - mae: 8.5523 - val_loss: 20.1126 - val_mae: 20.6100\n",
      "Epoch 19/500\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 8.0224 - mae: 8.5099 - val_loss: 19.8749 - val_mae: 20.3714\n",
      "Epoch 20/500\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 7.9928 - mae: 8.4768 - val_loss: 20.2180 - val_mae: 20.7162\n",
      "Epoch 21/500\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 7.9829 - mae: 8.4680 - val_loss: 19.6169 - val_mae: 20.1134\n",
      "Epoch 22/500\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 7.9538 - mae: 8.4386 - val_loss: 20.9318 - val_mae: 21.4290\n",
      "Epoch 23/500\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 8.0873 - mae: 8.5708 - val_loss: 19.2817 - val_mae: 19.7771\n",
      "Epoch 24/500\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 8.0385 - mae: 8.5228 - val_loss: 20.9646 - val_mae: 21.4629\n",
      "Epoch 25/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 8.0877 - mae: 8.5730 - val_loss: 20.1817 - val_mae: 20.6793\n",
      "Epoch 26/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 8.1095 - mae: 8.5919 - val_loss: 21.2086 - val_mae: 21.7056\n",
      "Epoch 27/500\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 8.1071 - mae: 8.5923 - val_loss: 20.2429 - val_mae: 20.7408\n",
      "Epoch 28/500\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 7.9957 - mae: 8.4816 - val_loss: 21.0968 - val_mae: 21.5916\n",
      "Epoch 29/500\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 8.0536 - mae: 8.5404 - val_loss: 19.6478 - val_mae: 20.1443\n",
      "Epoch 30/500\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 8.0155 - mae: 8.5024 - val_loss: 19.6770 - val_mae: 20.1735\n",
      "Epoch 31/500\n",
      "36/36 [==============================] - 1s 13ms/step - loss: 8.0165 - mae: 8.5034 - val_loss: 19.6679 - val_mae: 20.1644\n",
      "Epoch 32/500\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 8.0179 - mae: 8.5045 - val_loss: 19.6543 - val_mae: 20.1508\n",
      "Epoch 33/500\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 8.0138 - mae: 8.5007 - val_loss: 19.6543 - val_mae: 20.1507\n",
      "Epoch 34/500\n",
      "36/36 [==============================] - 1s 13ms/step - loss: 8.0127 - mae: 8.4999 - val_loss: 19.7162 - val_mae: 20.2129\n",
      "Epoch 35/500\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 8.0154 - mae: 8.5026 - val_loss: 19.7264 - val_mae: 20.2230\n",
      "Epoch 36/500\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 7.9167 - mae: 8.4018 - val_loss: 19.5020 - val_mae: 19.9972\n",
      "Epoch 37/500\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 8.0226 - mae: 8.5079 - val_loss: 19.4446 - val_mae: 19.9397\n",
      "Epoch 38/500\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 8.0101 - mae: 8.4967 - val_loss: 19.6025 - val_mae: 20.0987\n",
      "Epoch 39/500\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 7.9864 - mae: 8.4729 - val_loss: 19.5827 - val_mae: 20.0787\n",
      "Epoch 40/500\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 8.0206 - mae: 8.5067 - val_loss: 19.5303 - val_mae: 20.0260\n",
      "Epoch 41/500\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 8.0131 - mae: 8.4999 - val_loss: 19.6172 - val_mae: 20.1135\n",
      "Epoch 42/500\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 8.0120 - mae: 8.4990 - val_loss: 19.6731 - val_mae: 20.1696\n",
      "Epoch 43/500\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 8.0156 - mae: 8.5026 - val_loss: 19.6702 - val_mae: 20.1668\n",
      "Epoch 44/500\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 8.0154 - mae: 8.5025 - val_loss: 19.6776 - val_mae: 20.1742\n",
      "Epoch 45/500\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 8.0137 - mae: 8.5008 - val_loss: 19.6818 - val_mae: 20.1784\n",
      "Epoch 46/500\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 8.0120 - mae: 8.4990 - val_loss: 19.7129 - val_mae: 20.2092\n",
      "Epoch 47/500\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 7.9036 - mae: 8.3884 - val_loss: 20.0360 - val_mae: 20.5336\n",
      "Epoch 48/500\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 8.0428 - mae: 8.5275 - val_loss: 19.4247 - val_mae: 19.9198\n",
      "Epoch 49/500\n",
      "36/36 [==============================] - 1s 12ms/step - loss: 8.0134 - mae: 8.4997 - val_loss: 19.5533 - val_mae: 20.0492\n",
      "Epoch 50/500\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 8.0114 - mae: 8.4983 - val_loss: 19.6411 - val_mae: 20.1375\n",
      "Epoch 51/500\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 8.0140 - mae: 8.5009 - val_loss: 19.6648 - val_mae: 20.1613\n",
      "Epoch 52/500\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 8.0167 - mae: 8.5035 - val_loss: 19.6600 - val_mae: 20.1565\n",
      "Epoch 53/500\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 8.0135 - mae: 8.5005 - val_loss: 19.7019 - val_mae: 20.1986\n",
      "Epoch 54/500\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 8.0162 - mae: 8.5029 - val_loss: 19.6557 - val_mae: 20.1521\n",
      "Epoch 55/500\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 8.0143 - mae: 8.5012 - val_loss: 19.6817 - val_mae: 20.1783\n",
      "Epoch 56/500\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 8.0149 - mae: 8.5019 - val_loss: 19.7009 - val_mae: 20.1975\n",
      "Epoch 57/500\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 8.0167 - mae: 8.5036 - val_loss: 19.7030 - val_mae: 20.1996\n",
      "Epoch 58/500\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 8.0160 - mae: 8.5030 - val_loss: 19.6947 - val_mae: 20.1913\n",
      "Epoch 59/500\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 8.0159 - mae: 8.5028 - val_loss: 19.6996 - val_mae: 20.1962\n",
      "Epoch 60/500\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 8.0167 - mae: 8.5035 - val_loss: 19.6516 - val_mae: 20.1480\n",
      "Epoch 61/500\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 8.0153 - mae: 8.5024 - val_loss: 19.6794 - val_mae: 20.1759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/500\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 8.0188 - mae: 8.5055 - val_loss: 19.6419 - val_mae: 20.1383\n",
      "Epoch 63/500\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 8.0155 - mae: 8.5023 - val_loss: 19.6429 - val_mae: 20.1393\n",
      "Epoch 64/500\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 8.0145 - mae: 8.5015 - val_loss: 19.6531 - val_mae: 20.1495\n",
      "Epoch 65/500\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 8.0131 - mae: 8.5002 - val_loss: 19.7038 - val_mae: 20.2004\n",
      "Epoch 66/500\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 8.0158 - mae: 8.5026 - val_loss: 19.6782 - val_mae: 20.1747\n",
      "Epoch 67/500\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 8.0141 - mae: 8.5012 - val_loss: 19.7281 - val_mae: 20.2248\n",
      "Epoch 68/500\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 8.0146 - mae: 8.5016 - val_loss: 19.6718 - val_mae: 20.1683\n",
      "Epoch 69/500\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 8.0158 - mae: 8.5026 - val_loss: 19.6788 - val_mae: 20.1754\n",
      "Epoch 70/500\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 8.0162 - mae: 8.5031 - val_loss: 19.6793 - val_mae: 20.1758\n",
      "Epoch 71/500\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 8.0159 - mae: 8.5028 - val_loss: 19.6697 - val_mae: 20.1663\n",
      "Epoch 72/500\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 8.0165 - mae: 8.5033 - val_loss: 19.6636 - val_mae: 20.1601\n",
      "Epoch 73/500\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 8.0708 - mae: 8.5540 - val_loss: 21.1858 - val_mae: 21.6832\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 19.2817 - mae: 19.7771\n",
      "Sequence to Sequence Model Forecast MAE = 19777112.96081543\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "seq2seq_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(32, return_sequences=True, input_shape=[None,1]),\n",
    "    tf.keras.layers.Dense(14)\n",
    "])\n",
    "\n",
    "seq2seq_mae = fit_and_evaluate(seq2seq_model, seq2seq_train, seq2seq_valid, learning_rate=0.01)\n",
    "print(f\"Sequence to Sequence Model Forecast MAE = {seq2seq_mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6758cda",
   "metadata": {},
   "source": [
    "#### RNN With Layer Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "50738251",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LNSimpleRNNCell(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, activation=\"tanh\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.state_size = units\n",
    "        self.output_size = units\n",
    "        self.simple_rnn_cell = tf.keras.layers.SimpleRNNCell(units, activation=None) # no activation for LN\n",
    "        \n",
    "        self.layer_norm = tf.keras.layers.LayerNormalization()\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "        \n",
    "    def call(self, inputs, states):\n",
    "        outputs, new_states = self.simple_rnn_cell(inputs, states)\n",
    "        norm_outputs = self.activation(self.layer_norm(outputs))\n",
    "        return norm_outputs, [norm_outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d8b739d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "36/36 [==============================] - 3s 41ms/step - loss: 26.6080 - mae: 27.1080 - val_loss: 40.9161 - val_mae: 41.4161\n",
      "Epoch 2/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 21.5224 - mae: 22.0223 - val_loss: 34.7266 - val_mae: 35.2266\n",
      "Epoch 3/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 14.7166 - mae: 15.2109 - val_loss: 27.3436 - val_mae: 27.8433\n",
      "Epoch 4/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 9.5795 - mae: 10.0647 - val_loss: 22.2176 - val_mae: 22.7125\n",
      "Epoch 5/500\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 8.2214 - mae: 8.7055 - val_loss: 20.5117 - val_mae: 21.0105\n",
      "Epoch 6/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 8.0469 - mae: 8.5335 - val_loss: 19.9730 - val_mae: 20.4698\n",
      "Epoch 7/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 8.0179 - mae: 8.5054 - val_loss: 19.8019 - val_mae: 20.2987\n",
      "Epoch 8/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 8.0090 - mae: 8.4963 - val_loss: 19.7563 - val_mae: 20.2530\n",
      "Epoch 9/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 8.0030 - mae: 8.4902 - val_loss: 19.7842 - val_mae: 20.2809\n",
      "Epoch 10/500\n",
      "36/36 [==============================] - 1s 36ms/step - loss: 7.9941 - mae: 8.4816 - val_loss: 19.9122 - val_mae: 20.4088\n",
      "Epoch 11/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.9963 - mae: 8.4833 - val_loss: 19.8500 - val_mae: 20.3465\n",
      "Epoch 12/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.9774 - mae: 8.4644 - val_loss: 20.0924 - val_mae: 20.5904\n",
      "Epoch 13/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.9963 - mae: 8.4825 - val_loss: 19.8789 - val_mae: 20.3758\n",
      "Epoch 14/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.9552 - mae: 8.4413 - val_loss: 20.3044 - val_mae: 20.8032\n",
      "Epoch 15/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 8.0070 - mae: 8.4915 - val_loss: 19.9196 - val_mae: 20.4169\n",
      "Epoch 16/500\n",
      "36/36 [==============================] - 2s 43ms/step - loss: 7.9597 - mae: 8.4447 - val_loss: 20.1530 - val_mae: 20.6516\n",
      "Epoch 17/500\n",
      "36/36 [==============================] - 1s 38ms/step - loss: 7.9494 - mae: 8.4339 - val_loss: 20.1223 - val_mae: 20.6208\n",
      "Epoch 18/500\n",
      "36/36 [==============================] - 1s 37ms/step - loss: 7.9858 - mae: 8.4701 - val_loss: 20.1518 - val_mae: 20.6504\n",
      "Epoch 19/500\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 7.9529 - mae: 8.4374 - val_loss: 19.9094 - val_mae: 20.4071\n",
      "Epoch 20/500\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 7.9053 - mae: 8.3899 - val_loss: 19.5809 - val_mae: 20.0776\n",
      "Epoch 21/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 7.9095 - mae: 8.3941 - val_loss: 19.6559 - val_mae: 20.1530\n",
      "Epoch 22/500\n",
      "36/36 [==============================] - 2s 42ms/step - loss: 7.8900 - mae: 8.3746 - val_loss: 19.3510 - val_mae: 19.8473\n",
      "Epoch 23/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 7.8660 - mae: 8.3508 - val_loss: 18.8610 - val_mae: 19.3546\n",
      "Epoch 24/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 7.7970 - mae: 8.2808 - val_loss: 18.5907 - val_mae: 19.0833\n",
      "Epoch 25/500\n",
      "36/36 [==============================] - 1s 36ms/step - loss: 7.7911 - mae: 8.2745 - val_loss: 18.6576 - val_mae: 19.1507\n",
      "Epoch 26/500\n",
      "36/36 [==============================] - 2s 41ms/step - loss: 7.7457 - mae: 8.2286 - val_loss: 18.3549 - val_mae: 18.8470\n",
      "Epoch 27/500\n",
      "36/36 [==============================] - 2s 42ms/step - loss: 7.6914 - mae: 8.1741 - val_loss: 18.5618 - val_mae: 19.0550\n",
      "Epoch 28/500\n",
      "36/36 [==============================] - 2s 43ms/step - loss: 7.7886 - mae: 8.2716 - val_loss: 18.0099 - val_mae: 18.5008\n",
      "Epoch 29/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 7.6763 - mae: 8.1589 - val_loss: 18.3982 - val_mae: 18.8913\n",
      "Epoch 30/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.7332 - mae: 8.2160 - val_loss: 17.8569 - val_mae: 18.3475\n",
      "Epoch 31/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.6454 - mae: 8.1281 - val_loss: 18.2152 - val_mae: 18.7075\n",
      "Epoch 32/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.6981 - mae: 8.1809 - val_loss: 17.9014 - val_mae: 18.3926\n",
      "Epoch 33/500\n",
      "36/36 [==============================] - 1s 35ms/step - loss: 7.6497 - mae: 8.1323 - val_loss: 17.7593 - val_mae: 18.2504\n",
      "Epoch 34/500\n",
      "36/36 [==============================] - 2s 41ms/step - loss: 7.6462 - mae: 8.1288 - val_loss: 17.7205 - val_mae: 18.2120\n",
      "Epoch 35/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 7.6453 - mae: 8.1280 - val_loss: 17.8417 - val_mae: 18.3334\n",
      "Epoch 36/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.6324 - mae: 8.1151 - val_loss: 17.7881 - val_mae: 18.2799\n",
      "Epoch 37/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.6179 - mae: 8.1004 - val_loss: 17.5386 - val_mae: 18.0303\n",
      "Epoch 38/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 7.5589 - mae: 8.0413 - val_loss: 17.6523 - val_mae: 18.1440\n",
      "Epoch 39/500\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 7.6413 - mae: 8.1238 - val_loss: 17.6178 - val_mae: 18.1096\n",
      "Epoch 40/500\n",
      "36/36 [==============================] - 2s 40ms/step - loss: 7.5547 - mae: 8.0372 - val_loss: 17.7484 - val_mae: 18.2405\n",
      "Epoch 41/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 7.5862 - mae: 8.0686 - val_loss: 17.5254 - val_mae: 18.0169\n",
      "Epoch 42/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 7.5530 - mae: 8.0353 - val_loss: 17.3945 - val_mae: 17.8859\n",
      "Epoch 43/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 7.5676 - mae: 8.0502 - val_loss: 17.5852 - val_mae: 18.0772\n",
      "Epoch 44/500\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 7.5823 - mae: 8.0646 - val_loss: 17.5557 - val_mae: 18.0477\n",
      "Epoch 45/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 7.5529 - mae: 8.0351 - val_loss: 17.4562 - val_mae: 17.9480\n",
      "Epoch 46/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 7.5521 - mae: 8.0344 - val_loss: 17.4122 - val_mae: 17.9040\n",
      "Epoch 47/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.5323 - mae: 8.0146 - val_loss: 17.4679 - val_mae: 17.9600\n",
      "Epoch 48/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.5143 - mae: 7.9961 - val_loss: 17.1773 - val_mae: 17.6685\n",
      "Epoch 49/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 7.5261 - mae: 8.0082 - val_loss: 17.3238 - val_mae: 17.8154\n",
      "Epoch 50/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.4938 - mae: 7.9756 - val_loss: 17.4252 - val_mae: 17.9174\n",
      "Epoch 51/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.5363 - mae: 8.0184 - val_loss: 17.4548 - val_mae: 17.9470\n",
      "Epoch 52/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.5265 - mae: 8.0086 - val_loss: 17.2912 - val_mae: 17.7833\n",
      "Epoch 53/500\n",
      "36/36 [==============================] - 2s 40ms/step - loss: 7.5303 - mae: 8.0124 - val_loss: 17.1304 - val_mae: 17.6207\n",
      "Epoch 54/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.4861 - mae: 7.9679 - val_loss: 17.2391 - val_mae: 17.7307\n",
      "Epoch 55/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.5010 - mae: 7.9828 - val_loss: 17.3205 - val_mae: 17.8127\n",
      "Epoch 56/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.5196 - mae: 8.0014 - val_loss: 17.1719 - val_mae: 17.6633\n",
      "Epoch 57/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.5116 - mae: 7.9934 - val_loss: 17.3106 - val_mae: 17.8024\n",
      "Epoch 58/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.4913 - mae: 7.9731 - val_loss: 17.2640 - val_mae: 17.7561\n",
      "Epoch 59/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.5117 - mae: 7.9936 - val_loss: 17.1177 - val_mae: 17.6091\n",
      "Epoch 60/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.5116 - mae: 7.9934 - val_loss: 17.0976 - val_mae: 17.5886\n",
      "Epoch 61/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.4688 - mae: 7.9505 - val_loss: 17.1609 - val_mae: 17.6528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.4865 - mae: 7.9684 - val_loss: 16.9250 - val_mae: 17.4151\n",
      "Epoch 63/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 7.4771 - mae: 7.9587 - val_loss: 17.1251 - val_mae: 17.6166\n",
      "Epoch 64/500\n",
      "36/36 [==============================] - 1s 34ms/step - loss: 7.4856 - mae: 7.9674 - val_loss: 17.0579 - val_mae: 17.5492\n",
      "Epoch 65/500\n",
      "36/36 [==============================] - 1s 35ms/step - loss: 7.4822 - mae: 7.9643 - val_loss: 17.0045 - val_mae: 17.4954\n",
      "Epoch 66/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 7.4608 - mae: 7.9424 - val_loss: 16.9192 - val_mae: 17.4096\n",
      "Epoch 67/500\n",
      "36/36 [==============================] - 1s 36ms/step - loss: 7.4558 - mae: 7.9375 - val_loss: 16.9600 - val_mae: 17.4508\n",
      "Epoch 68/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.4677 - mae: 7.9494 - val_loss: 16.7820 - val_mae: 17.2715\n",
      "Epoch 69/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.4531 - mae: 7.9348 - val_loss: 16.9069 - val_mae: 17.3969\n",
      "Epoch 70/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.4596 - mae: 7.9413 - val_loss: 16.9164 - val_mae: 17.4070\n",
      "Epoch 71/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.4651 - mae: 7.9469 - val_loss: 16.9862 - val_mae: 17.4776\n",
      "Epoch 72/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 7.4590 - mae: 7.9408 - val_loss: 16.8742 - val_mae: 17.3647\n",
      "Epoch 73/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.4747 - mae: 7.9565 - val_loss: 16.8417 - val_mae: 17.3322\n",
      "Epoch 74/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.4417 - mae: 7.9234 - val_loss: 16.7601 - val_mae: 17.2495\n",
      "Epoch 75/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.4339 - mae: 7.9154 - val_loss: 16.7983 - val_mae: 17.2878\n",
      "Epoch 76/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.4603 - mae: 7.9420 - val_loss: 16.7451 - val_mae: 17.2345\n",
      "Epoch 77/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.4375 - mae: 7.9191 - val_loss: 16.9249 - val_mae: 17.4163\n",
      "Epoch 78/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.4650 - mae: 7.9470 - val_loss: 16.9838 - val_mae: 17.4760\n",
      "Epoch 79/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.4812 - mae: 7.9633 - val_loss: 16.7754 - val_mae: 17.2646\n",
      "Epoch 80/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.4467 - mae: 7.9284 - val_loss: 16.7331 - val_mae: 17.2226\n",
      "Epoch 81/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.4425 - mae: 7.9243 - val_loss: 16.7285 - val_mae: 17.2179\n",
      "Epoch 82/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.4528 - mae: 7.9346 - val_loss: 16.8953 - val_mae: 17.3866\n",
      "Epoch 83/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.4470 - mae: 7.9288 - val_loss: 16.6470 - val_mae: 17.1367\n",
      "Epoch 84/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.4700 - mae: 7.9517 - val_loss: 16.7599 - val_mae: 17.2492\n",
      "Epoch 85/500\n",
      "36/36 [==============================] - 2s 40ms/step - loss: 7.4384 - mae: 7.9201 - val_loss: 16.5603 - val_mae: 17.0498\n",
      "Epoch 86/500\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 7.4287 - mae: 7.9103 - val_loss: 16.6512 - val_mae: 17.1406\n",
      "Epoch 87/500\n",
      "36/36 [==============================] - 1s 36ms/step - loss: 7.4488 - mae: 7.9304 - val_loss: 16.5639 - val_mae: 17.0541\n",
      "Epoch 88/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.4295 - mae: 7.9111 - val_loss: 16.6714 - val_mae: 17.1608\n",
      "Epoch 89/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.4446 - mae: 7.9264 - val_loss: 16.6254 - val_mae: 17.1153\n",
      "Epoch 90/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.4617 - mae: 7.9437 - val_loss: 16.7616 - val_mae: 17.2520\n",
      "Epoch 91/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.4501 - mae: 7.9321 - val_loss: 16.7617 - val_mae: 17.2520\n",
      "Epoch 92/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.4360 - mae: 7.9179 - val_loss: 16.6175 - val_mae: 17.1071\n",
      "Epoch 93/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.4383 - mae: 7.9201 - val_loss: 16.6802 - val_mae: 17.1693\n",
      "Epoch 94/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.4449 - mae: 7.9268 - val_loss: 16.6079 - val_mae: 17.0976\n",
      "Epoch 95/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.4318 - mae: 7.9137 - val_loss: 16.7089 - val_mae: 17.1987\n",
      "Epoch 96/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.4404 - mae: 7.9224 - val_loss: 16.5867 - val_mae: 17.0767\n",
      "Epoch 97/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.4221 - mae: 7.9038 - val_loss: 16.4588 - val_mae: 16.9482\n",
      "Epoch 98/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.4252 - mae: 7.9071 - val_loss: 16.5343 - val_mae: 17.0245\n",
      "Epoch 99/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.4359 - mae: 7.9177 - val_loss: 16.5428 - val_mae: 17.0331\n",
      "Epoch 100/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.4430 - mae: 7.9250 - val_loss: 16.5041 - val_mae: 16.9940\n",
      "Epoch 101/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.4243 - mae: 7.9061 - val_loss: 16.5275 - val_mae: 17.0176\n",
      "Epoch 102/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.4343 - mae: 7.9163 - val_loss: 16.6250 - val_mae: 17.1141\n",
      "Epoch 103/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.4370 - mae: 7.9191 - val_loss: 16.5464 - val_mae: 17.0364\n",
      "Epoch 104/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.4417 - mae: 7.9237 - val_loss: 16.4835 - val_mae: 16.9736\n",
      "Epoch 105/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.4137 - mae: 7.8957 - val_loss: 16.5764 - val_mae: 17.0655\n",
      "Epoch 106/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.4416 - mae: 7.9237 - val_loss: 16.5945 - val_mae: 17.0837\n",
      "Epoch 107/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.4304 - mae: 7.9124 - val_loss: 16.5585 - val_mae: 17.0478\n",
      "Epoch 108/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.4439 - mae: 7.9259 - val_loss: 16.4328 - val_mae: 16.9227\n",
      "Epoch 109/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.4441 - mae: 7.9261 - val_loss: 16.4302 - val_mae: 16.9203\n",
      "Epoch 110/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.4097 - mae: 7.8918 - val_loss: 16.5784 - val_mae: 17.0672\n",
      "Epoch 111/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.4232 - mae: 7.9053 - val_loss: 16.5217 - val_mae: 17.0114\n",
      "Epoch 112/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.4335 - mae: 7.9156 - val_loss: 16.6062 - val_mae: 17.0953\n",
      "Epoch 113/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.4393 - mae: 7.9215 - val_loss: 16.5282 - val_mae: 17.0175\n",
      "Epoch 114/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.4207 - mae: 7.9028 - val_loss: 16.4899 - val_mae: 16.9799\n",
      "Epoch 115/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.4264 - mae: 7.9084 - val_loss: 16.3527 - val_mae: 16.8425\n",
      "Epoch 116/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.4116 - mae: 7.8937 - val_loss: 16.5587 - val_mae: 17.0476\n",
      "Epoch 117/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.4405 - mae: 7.9226 - val_loss: 16.4884 - val_mae: 16.9779\n",
      "Epoch 118/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 7.4263 - mae: 7.9083 - val_loss: 16.5532 - val_mae: 17.0421\n",
      "Epoch 119/500\n",
      "36/36 [==============================] - 1s 37ms/step - loss: 7.4346 - mae: 7.9166 - val_loss: 16.3349 - val_mae: 16.8251\n",
      "Epoch 120/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 7.4158 - mae: 7.8978 - val_loss: 16.3286 - val_mae: 16.8190\n",
      "Epoch 121/500\n",
      "36/36 [==============================] - 1s 38ms/step - loss: 7.4275 - mae: 7.9096 - val_loss: 16.4770 - val_mae: 16.9664\n",
      "Epoch 122/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 2s 39ms/step - loss: 7.4198 - mae: 7.9020 - val_loss: 16.3968 - val_mae: 16.8873\n",
      "Epoch 123/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 7.4262 - mae: 7.9084 - val_loss: 16.4135 - val_mae: 16.9032\n",
      "Epoch 124/500\n",
      "36/36 [==============================] - 1s 39ms/step - loss: 7.4109 - mae: 7.8931 - val_loss: 16.4614 - val_mae: 16.9515\n",
      "Epoch 125/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 7.4443 - mae: 7.9266 - val_loss: 16.5249 - val_mae: 17.0139\n",
      "Epoch 126/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 7.4445 - mae: 7.9268 - val_loss: 16.3428 - val_mae: 16.8327\n",
      "Epoch 127/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.4225 - mae: 7.9046 - val_loss: 16.4338 - val_mae: 16.9241\n",
      "Epoch 128/500\n",
      "36/36 [==============================] - 2s 40ms/step - loss: 7.4162 - mae: 7.8984 - val_loss: 16.4817 - val_mae: 16.9711\n",
      "Epoch 129/500\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 7.4208 - mae: 7.9030 - val_loss: 16.5455 - val_mae: 17.0346\n",
      "Epoch 130/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 7.4354 - mae: 7.9178 - val_loss: 16.4394 - val_mae: 16.9293\n",
      "Epoch 131/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 7.4173 - mae: 7.8995 - val_loss: 16.4843 - val_mae: 16.9737\n",
      "Epoch 132/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 7.4211 - mae: 7.9032 - val_loss: 16.4028 - val_mae: 16.8932\n",
      "Epoch 133/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 7.4160 - mae: 7.8984 - val_loss: 16.6738 - val_mae: 17.1644\n",
      "Epoch 134/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 7.4234 - mae: 7.9058 - val_loss: 16.5537 - val_mae: 17.0432\n",
      "Epoch 135/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 7.4357 - mae: 7.9181 - val_loss: 16.4672 - val_mae: 16.9570\n",
      "Epoch 136/500\n",
      "36/36 [==============================] - 2s 43ms/step - loss: 7.4196 - mae: 7.9018 - val_loss: 16.5026 - val_mae: 16.9921\n",
      "Epoch 137/500\n",
      "36/36 [==============================] - 1s 38ms/step - loss: 7.4189 - mae: 7.9010 - val_loss: 16.4235 - val_mae: 16.9140\n",
      "Epoch 138/500\n",
      "36/36 [==============================] - 1s 34ms/step - loss: 7.4218 - mae: 7.9039 - val_loss: 16.4355 - val_mae: 16.9254\n",
      "Epoch 139/500\n",
      "36/36 [==============================] - 2s 43ms/step - loss: 7.4132 - mae: 7.8956 - val_loss: 16.3837 - val_mae: 16.8743\n",
      "Epoch 140/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 7.4233 - mae: 7.9056 - val_loss: 16.3700 - val_mae: 16.8602\n",
      "Epoch 141/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 7.4175 - mae: 7.8997 - val_loss: 16.4618 - val_mae: 16.9514\n",
      "Epoch 142/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 7.4210 - mae: 7.9034 - val_loss: 16.4422 - val_mae: 16.9321\n",
      "Epoch 143/500\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 7.4253 - mae: 7.9076 - val_loss: 16.4290 - val_mae: 16.9190\n",
      "Epoch 144/500\n",
      "36/36 [==============================] - 1s 38ms/step - loss: 7.4223 - mae: 7.9047 - val_loss: 16.4318 - val_mae: 16.9218\n",
      "Epoch 145/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 7.4002 - mae: 7.8825 - val_loss: 16.4772 - val_mae: 16.9669\n",
      "Epoch 146/500\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 7.4244 - mae: 7.9067 - val_loss: 16.3923 - val_mae: 16.8824\n",
      "Epoch 147/500\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 7.4133 - mae: 7.8957 - val_loss: 16.3819 - val_mae: 16.8721\n",
      "Epoch 148/500\n",
      "36/36 [==============================] - 2s 42ms/step - loss: 7.4208 - mae: 7.9032 - val_loss: 16.4814 - val_mae: 16.9709\n",
      "Epoch 149/500\n",
      "36/36 [==============================] - 1s 37ms/step - loss: 7.4286 - mae: 7.9109 - val_loss: 16.2808 - val_mae: 16.7714\n",
      "Epoch 150/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.4151 - mae: 7.8974 - val_loss: 16.3238 - val_mae: 16.8141\n",
      "Epoch 151/500\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 7.4164 - mae: 7.8986 - val_loss: 16.4341 - val_mae: 16.9242\n",
      "Epoch 152/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.4169 - mae: 7.8992 - val_loss: 16.3451 - val_mae: 16.8352\n",
      "Epoch 153/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 7.4200 - mae: 7.9022 - val_loss: 16.3491 - val_mae: 16.8395\n",
      "Epoch 154/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 7.4022 - mae: 7.8844 - val_loss: 16.4400 - val_mae: 16.9298\n",
      "Epoch 155/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 7.4239 - mae: 7.9062 - val_loss: 16.2697 - val_mae: 16.7602\n",
      "Epoch 156/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.4151 - mae: 7.8974 - val_loss: 16.4037 - val_mae: 16.8935\n",
      "Epoch 157/500\n",
      "36/36 [==============================] - 1s 34ms/step - loss: 7.4153 - mae: 7.8977 - val_loss: 16.3562 - val_mae: 16.8466\n",
      "Epoch 158/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 7.3987 - mae: 7.8810 - val_loss: 16.4248 - val_mae: 16.9148\n",
      "Epoch 159/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 7.4156 - mae: 7.8978 - val_loss: 16.4192 - val_mae: 16.9089\n",
      "Epoch 160/500\n",
      "36/36 [==============================] - 2s 41ms/step - loss: 7.4126 - mae: 7.8948 - val_loss: 16.4406 - val_mae: 16.9303\n",
      "Epoch 161/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 7.4185 - mae: 7.9010 - val_loss: 16.3727 - val_mae: 16.8629\n",
      "Epoch 162/500\n",
      "36/36 [==============================] - 2s 41ms/step - loss: 7.4081 - mae: 7.8904 - val_loss: 16.4255 - val_mae: 16.9153\n",
      "Epoch 163/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 7.4059 - mae: 7.8883 - val_loss: 16.4380 - val_mae: 16.9277\n",
      "Epoch 164/500\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 7.4154 - mae: 7.8978 - val_loss: 16.4150 - val_mae: 16.9051\n",
      "Epoch 165/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.4023 - mae: 7.8847 - val_loss: 16.5661 - val_mae: 17.0567\n",
      "Epoch 166/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.4260 - mae: 7.9085 - val_loss: 16.3897 - val_mae: 16.8800\n",
      "Epoch 167/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 7.4141 - mae: 7.8964 - val_loss: 16.3545 - val_mae: 16.8449\n",
      "Epoch 168/500\n",
      "36/36 [==============================] - 1s 38ms/step - loss: 7.3951 - mae: 7.8773 - val_loss: 16.4696 - val_mae: 16.9592\n",
      "Epoch 169/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.4174 - mae: 7.8998 - val_loss: 16.4435 - val_mae: 16.9330\n",
      "Epoch 170/500\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 7.4262 - mae: 7.9087 - val_loss: 16.4648 - val_mae: 16.9540\n",
      "Epoch 171/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.4225 - mae: 7.9047 - val_loss: 16.3076 - val_mae: 16.7980\n",
      "Epoch 172/500\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 7.4221 - mae: 7.9045 - val_loss: 16.3953 - val_mae: 16.8851\n",
      "Epoch 173/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 7.4268 - mae: 7.9093 - val_loss: 16.2749 - val_mae: 16.7654\n",
      "Epoch 174/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 7.4171 - mae: 7.8994 - val_loss: 16.3152 - val_mae: 16.8055\n",
      "Epoch 175/500\n",
      "36/36 [==============================] - 1s 38ms/step - loss: 7.4287 - mae: 7.9111 - val_loss: 16.2466 - val_mae: 16.7370\n",
      "Epoch 176/500\n",
      "36/36 [==============================] - 1s 34ms/step - loss: 7.3957 - mae: 7.8780 - val_loss: 16.3715 - val_mae: 16.8617\n",
      "Epoch 177/500\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 7.4122 - mae: 7.8945 - val_loss: 16.3696 - val_mae: 16.8599\n",
      "Epoch 178/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.4136 - mae: 7.8959 - val_loss: 16.4156 - val_mae: 16.9049\n",
      "Epoch 179/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.4141 - mae: 7.8966 - val_loss: 16.4267 - val_mae: 16.9162\n",
      "Epoch 180/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 7.4005 - mae: 7.8827 - val_loss: 16.4802 - val_mae: 16.9700\n",
      "Epoch 181/500\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 7.4164 - mae: 7.8988 - val_loss: 16.4101 - val_mae: 16.9000\n",
      "Epoch 182/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 2s 39ms/step - loss: 7.4438 - mae: 7.9262 - val_loss: 16.3422 - val_mae: 16.8317\n",
      "Epoch 183/500\n",
      "36/36 [==============================] - 1s 36ms/step - loss: 7.4099 - mae: 7.8921 - val_loss: 16.3307 - val_mae: 16.8213\n",
      "Epoch 184/500\n",
      "36/36 [==============================] - 1s 34ms/step - loss: 7.4029 - mae: 7.8853 - val_loss: 16.3597 - val_mae: 16.8502\n",
      "Epoch 185/500\n",
      "36/36 [==============================] - 1s 37ms/step - loss: 7.4079 - mae: 7.8902 - val_loss: 16.4013 - val_mae: 16.8911\n",
      "Epoch 186/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 7.3908 - mae: 7.8730 - val_loss: 16.4184 - val_mae: 16.9083\n",
      "Epoch 187/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 7.4060 - mae: 7.8882 - val_loss: 16.4187 - val_mae: 16.9085\n",
      "Epoch 188/500\n",
      "36/36 [==============================] - 1s 35ms/step - loss: 7.4135 - mae: 7.8958 - val_loss: 16.3812 - val_mae: 16.8712\n",
      "Epoch 189/500\n",
      "36/36 [==============================] - 1s 35ms/step - loss: 7.4161 - mae: 7.8984 - val_loss: 16.4621 - val_mae: 16.9519\n",
      "Epoch 190/500\n",
      "36/36 [==============================] - 1s 34ms/step - loss: 7.4110 - mae: 7.8935 - val_loss: 16.4122 - val_mae: 16.9018\n",
      "Epoch 191/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 7.4207 - mae: 7.9031 - val_loss: 16.4055 - val_mae: 16.8949\n",
      "Epoch 192/500\n",
      "36/36 [==============================] - 2s 40ms/step - loss: 7.4012 - mae: 7.8835 - val_loss: 16.4978 - val_mae: 16.9880\n",
      "Epoch 193/500\n",
      "36/36 [==============================] - 1s 36ms/step - loss: 7.4158 - mae: 7.8982 - val_loss: 16.4342 - val_mae: 16.9236\n",
      "Epoch 194/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 7.4104 - mae: 7.8929 - val_loss: 16.4952 - val_mae: 16.9856\n",
      "Epoch 195/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 7.4102 - mae: 7.8926 - val_loss: 16.4741 - val_mae: 16.9639\n",
      "Epoch 196/500\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 7.4016 - mae: 7.8841 - val_loss: 16.4509 - val_mae: 16.9406\n",
      "Epoch 197/500\n",
      "36/36 [==============================] - 1s 36ms/step - loss: 7.4012 - mae: 7.8836 - val_loss: 16.5047 - val_mae: 16.9952\n",
      "Epoch 198/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.4124 - mae: 7.8948 - val_loss: 16.3870 - val_mae: 16.8768\n",
      "Epoch 199/500\n",
      "36/36 [==============================] - 1s 34ms/step - loss: 7.4111 - mae: 7.8936 - val_loss: 16.4317 - val_mae: 16.9213\n",
      "Epoch 200/500\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 7.4099 - mae: 7.8924 - val_loss: 16.4470 - val_mae: 16.9368\n",
      "Epoch 201/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 7.4002 - mae: 7.8825 - val_loss: 16.4052 - val_mae: 16.8947\n",
      "Epoch 202/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 7.4087 - mae: 7.8909 - val_loss: 16.2908 - val_mae: 16.7813\n",
      "Epoch 203/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.3980 - mae: 7.8802 - val_loss: 16.4147 - val_mae: 16.9041\n",
      "Epoch 204/500\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 7.4115 - mae: 7.8939 - val_loss: 16.5615 - val_mae: 17.0520\n",
      "Epoch 205/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 7.4346 - mae: 7.9173 - val_loss: 16.4686 - val_mae: 16.9589\n",
      "Epoch 206/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.4213 - mae: 7.9039 - val_loss: 16.3654 - val_mae: 16.8556\n",
      "Epoch 207/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.3975 - mae: 7.8798 - val_loss: 16.3587 - val_mae: 16.8492\n",
      "Epoch 208/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.4086 - mae: 7.8908 - val_loss: 16.4420 - val_mae: 16.9320\n",
      "Epoch 209/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.4143 - mae: 7.8969 - val_loss: 16.4322 - val_mae: 16.9222\n",
      "Epoch 210/500\n",
      "36/36 [==============================] - 1s 35ms/step - loss: 7.4118 - mae: 7.8942 - val_loss: 16.4098 - val_mae: 16.8991\n",
      "Epoch 211/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 7.4056 - mae: 7.8879 - val_loss: 16.4873 - val_mae: 16.9776\n",
      "Epoch 212/500\n",
      "36/36 [==============================] - 1s 34ms/step - loss: 7.4074 - mae: 7.8899 - val_loss: 16.5187 - val_mae: 17.0094\n",
      "Epoch 213/500\n",
      "36/36 [==============================] - 1s 34ms/step - loss: 7.4012 - mae: 7.8838 - val_loss: 16.5177 - val_mae: 17.0086\n",
      "Epoch 214/500\n",
      "36/36 [==============================] - 2s 42ms/step - loss: 7.4193 - mae: 7.9017 - val_loss: 16.4100 - val_mae: 16.8996\n",
      "Epoch 215/500\n",
      "36/36 [==============================] - 1s 34ms/step - loss: 7.4079 - mae: 7.8902 - val_loss: 16.3543 - val_mae: 16.8443\n",
      "Epoch 216/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.4085 - mae: 7.8907 - val_loss: 16.3740 - val_mae: 16.8638\n",
      "Epoch 217/500\n",
      "36/36 [==============================] - 1s 35ms/step - loss: 7.3980 - mae: 7.8802 - val_loss: 16.4178 - val_mae: 16.9074\n",
      "Epoch 218/500\n",
      "36/36 [==============================] - 2s 39ms/step - loss: 7.4178 - mae: 7.9002 - val_loss: 16.3779 - val_mae: 16.8675\n",
      "Epoch 219/500\n",
      "36/36 [==============================] - 1s 37ms/step - loss: 7.3944 - mae: 7.8770 - val_loss: 16.4206 - val_mae: 16.9105\n",
      "Epoch 220/500\n",
      "36/36 [==============================] - 1s 34ms/step - loss: 7.4077 - mae: 7.8901 - val_loss: 16.4503 - val_mae: 16.9401\n",
      "Epoch 221/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 7.4015 - mae: 7.8838 - val_loss: 16.3879 - val_mae: 16.8775\n",
      "Epoch 222/500\n",
      "36/36 [==============================] - 1s 35ms/step - loss: 7.4067 - mae: 7.8890 - val_loss: 16.3535 - val_mae: 16.8433\n",
      "Epoch 223/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.4116 - mae: 7.8940 - val_loss: 16.3396 - val_mae: 16.8293\n",
      "Epoch 224/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 7.4105 - mae: 7.8928 - val_loss: 16.3947 - val_mae: 16.8843\n",
      "Epoch 225/500\n",
      "36/36 [==============================] - 1s 34ms/step - loss: 7.4172 - mae: 7.8996 - val_loss: 16.3740 - val_mae: 16.8636\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 16.2466 - mae: 16.7370\n",
      "RNN With Layer Normalization Model Forecast MAE = 16737026.21459961\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "custom_ln_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.RNN(LNSimpleRNNCell(32), return_sequences=True, input_shape=[None,1]),\n",
    "    tf.keras.layers.Dense(14)\n",
    "])\n",
    "\n",
    "ln_rnn_mae = fit_and_evaluate(custom_ln_model, seq2seq_train, seq2seq_valid, learning_rate=0.01)\n",
    "print(f\"RNN With Layer Normalization Model Forecast MAE = {ln_rnn_mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cecf494",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "666421bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "36/36 [==============================] - 4s 46ms/step - loss: 26.7633 - mae: 27.2633 - val_loss: 41.8186 - val_mae: 42.3186\n",
      "Epoch 2/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 23.1261 - mae: 23.6260 - val_loss: 37.2733 - val_mae: 37.7733\n",
      "Epoch 3/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 18.1213 - mae: 18.6204 - val_loss: 31.8831 - val_mae: 32.3831\n",
      "Epoch 4/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 13.0021 - mae: 13.4936 - val_loss: 26.6353 - val_mae: 27.1349\n",
      "Epoch 5/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 9.5622 - mae: 10.0474 - val_loss: 22.7921 - val_mae: 23.2890\n",
      "Epoch 6/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 8.3747 - mae: 8.8568 - val_loss: 21.0499 - val_mae: 21.5485\n",
      "Epoch 7/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 8.1180 - mae: 8.6027 - val_loss: 20.3204 - val_mae: 20.8184\n",
      "Epoch 8/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 8.0570 - mae: 8.5442 - val_loss: 19.9991 - val_mae: 20.4958\n",
      "Epoch 9/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 8.0330 - mae: 8.5201 - val_loss: 19.9945 - val_mae: 20.4912\n",
      "Epoch 10/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 8.0399 - mae: 8.5265 - val_loss: 19.6761 - val_mae: 20.1720\n",
      "Epoch 11/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 8.0159 - mae: 8.5027 - val_loss: 20.0921 - val_mae: 20.5890\n",
      "Epoch 12/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 7.9890 - mae: 8.4756 - val_loss: 20.3632 - val_mae: 20.8619\n",
      "Epoch 13/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.9809 - mae: 8.4655 - val_loss: 20.3879 - val_mae: 20.8866\n",
      "Epoch 14/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 7.9938 - mae: 8.4786 - val_loss: 20.4983 - val_mae: 20.9973\n",
      "Epoch 15/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 8.0106 - mae: 8.4968 - val_loss: 20.3621 - val_mae: 20.8611\n",
      "Epoch 16/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 8.0241 - mae: 8.5104 - val_loss: 20.1278 - val_mae: 20.6250\n",
      "Epoch 17/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 7.9950 - mae: 8.4806 - val_loss: 20.1377 - val_mae: 20.6357\n",
      "Epoch 18/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 7.9996 - mae: 8.4853 - val_loss: 19.8440 - val_mae: 20.3404\n",
      "Epoch 19/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 8.0201 - mae: 8.5062 - val_loss: 19.8542 - val_mae: 20.3508\n",
      "Epoch 20/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.9920 - mae: 8.4785 - val_loss: 19.5690 - val_mae: 20.0644\n",
      "Epoch 21/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.9776 - mae: 8.4647 - val_loss: 20.1302 - val_mae: 20.6280\n",
      "Epoch 22/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 8.0262 - mae: 8.5121 - val_loss: 19.4424 - val_mae: 19.9374\n",
      "Epoch 23/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 7.9933 - mae: 8.4799 - val_loss: 19.4681 - val_mae: 19.9632\n",
      "Epoch 24/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 7.9505 - mae: 8.4368 - val_loss: 19.5177 - val_mae: 20.0133\n",
      "Epoch 25/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.9727 - mae: 8.4586 - val_loss: 20.2790 - val_mae: 20.7770\n",
      "Epoch 26/500\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 8.0035 - mae: 8.4894 - val_loss: 20.0099 - val_mae: 20.5070\n",
      "Epoch 27/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 8.0017 - mae: 8.4851 - val_loss: 20.6833 - val_mae: 21.1824\n",
      "Epoch 28/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 8.0249 - mae: 8.5081 - val_loss: 20.2040 - val_mae: 20.7020\n",
      "Epoch 29/500\n",
      "36/36 [==============================] - 1s 35ms/step - loss: 7.9701 - mae: 8.4552 - val_loss: 19.8800 - val_mae: 20.3768\n",
      "Epoch 30/500\n",
      "36/36 [==============================] - 1s 35ms/step - loss: 7.9520 - mae: 8.4379 - val_loss: 20.1176 - val_mae: 20.6157\n",
      "Epoch 31/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.9700 - mae: 8.4556 - val_loss: 19.4586 - val_mae: 19.9539\n",
      "Epoch 32/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 7.9086 - mae: 8.3929 - val_loss: 19.1072 - val_mae: 19.6011\n",
      "Epoch 33/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 7.8960 - mae: 8.3815 - val_loss: 19.9549 - val_mae: 20.4526\n",
      "Epoch 34/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.9423 - mae: 8.4285 - val_loss: 20.2487 - val_mae: 20.7466\n",
      "Epoch 35/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 7.9732 - mae: 8.4582 - val_loss: 19.9376 - val_mae: 20.4347\n",
      "Epoch 36/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 7.9459 - mae: 8.4320 - val_loss: 19.7639 - val_mae: 20.2605\n",
      "Epoch 37/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.9346 - mae: 8.4212 - val_loss: 19.5306 - val_mae: 20.0261\n",
      "Epoch 38/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 7.8923 - mae: 8.3787 - val_loss: 19.5909 - val_mae: 20.0870\n",
      "Epoch 39/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.9182 - mae: 8.4050 - val_loss: 19.3880 - val_mae: 19.8836\n",
      "Epoch 40/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.8665 - mae: 8.3525 - val_loss: 19.3578 - val_mae: 19.8533\n",
      "Epoch 41/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.8794 - mae: 8.3653 - val_loss: 19.1130 - val_mae: 19.6072\n",
      "Epoch 42/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.8368 - mae: 8.3226 - val_loss: 19.1801 - val_mae: 19.6744\n",
      "Epoch 43/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.8493 - mae: 8.3349 - val_loss: 19.1393 - val_mae: 19.6335\n",
      "Epoch 44/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.7932 - mae: 8.2779 - val_loss: 19.2206 - val_mae: 19.7160\n",
      "Epoch 45/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 7.8187 - mae: 8.3042 - val_loss: 19.0497 - val_mae: 19.5438\n",
      "Epoch 46/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.8114 - mae: 8.2969 - val_loss: 18.9704 - val_mae: 19.4643\n",
      "Epoch 47/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 7.7961 - mae: 8.2814 - val_loss: 19.0989 - val_mae: 19.5935\n",
      "Epoch 48/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.8103 - mae: 8.2956 - val_loss: 18.9590 - val_mae: 19.4534\n",
      "Epoch 49/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 7.7864 - mae: 8.2711 - val_loss: 18.9042 - val_mae: 19.3982\n",
      "Epoch 50/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.7815 - mae: 8.2659 - val_loss: 18.8637 - val_mae: 19.3576\n",
      "Epoch 51/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.7516 - mae: 8.2356 - val_loss: 18.9445 - val_mae: 19.4389\n",
      "Epoch 52/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 7.7544 - mae: 8.2383 - val_loss: 18.6961 - val_mae: 19.1897\n",
      "Epoch 53/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 7.7032 - mae: 8.1862 - val_loss: 19.2384 - val_mae: 19.7344\n",
      "Epoch 54/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 7.7323 - mae: 8.2155 - val_loss: 18.8340 - val_mae: 19.3281\n",
      "Epoch 55/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 7.7383 - mae: 8.2219 - val_loss: 18.5625 - val_mae: 19.0557\n",
      "Epoch 56/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.6893 - mae: 8.1720 - val_loss: 18.5468 - val_mae: 19.0393\n",
      "Epoch 57/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 7.7711 - mae: 8.2547 - val_loss: 18.5667 - val_mae: 19.0591\n",
      "Epoch 58/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 7.6607 - mae: 8.1435 - val_loss: 18.2511 - val_mae: 18.7420\n",
      "Epoch 59/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 7.6390 - mae: 8.1216 - val_loss: 18.5505 - val_mae: 19.0430\n",
      "Epoch 60/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 7.6836 - mae: 8.1664 - val_loss: 18.3634 - val_mae: 18.8557\n",
      "Epoch 61/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 7.6361 - mae: 8.1184 - val_loss: 18.1991 - val_mae: 18.6900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 7.6517 - mae: 8.1339 - val_loss: 18.3207 - val_mae: 18.8121\n",
      "Epoch 63/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 7.6302 - mae: 8.1129 - val_loss: 18.3560 - val_mae: 18.8473\n",
      "Epoch 64/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 7.6431 - mae: 8.1254 - val_loss: 18.1187 - val_mae: 18.6100\n",
      "Epoch 65/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.6293 - mae: 8.1117 - val_loss: 18.2785 - val_mae: 18.7696\n",
      "Epoch 66/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 7.6139 - mae: 8.0962 - val_loss: 18.2236 - val_mae: 18.7160\n",
      "Epoch 67/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.6214 - mae: 8.1035 - val_loss: 17.9996 - val_mae: 18.4906\n",
      "Epoch 68/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.5466 - mae: 8.0284 - val_loss: 18.1288 - val_mae: 18.6201\n",
      "Epoch 69/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 7.5728 - mae: 8.0548 - val_loss: 17.9701 - val_mae: 18.4608\n",
      "Epoch 70/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 7.5804 - mae: 8.0621 - val_loss: 17.9174 - val_mae: 18.4075\n",
      "Epoch 71/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 7.5546 - mae: 8.0364 - val_loss: 17.8741 - val_mae: 18.3646\n",
      "Epoch 72/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 7.5620 - mae: 8.0438 - val_loss: 17.8787 - val_mae: 18.3692\n",
      "Epoch 73/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.5893 - mae: 8.0721 - val_loss: 17.8353 - val_mae: 18.3261\n",
      "Epoch 74/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.5555 - mae: 8.0376 - val_loss: 17.8399 - val_mae: 18.3299\n",
      "Epoch 75/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 7.5392 - mae: 8.0213 - val_loss: 17.8608 - val_mae: 18.3518\n",
      "Epoch 76/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.5661 - mae: 8.0482 - val_loss: 17.6417 - val_mae: 18.1324\n",
      "Epoch 77/500\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 7.5393 - mae: 8.0212 - val_loss: 17.4237 - val_mae: 17.9155\n",
      "Epoch 78/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 7.5291 - mae: 8.0111 - val_loss: 17.7153 - val_mae: 18.2063\n",
      "Epoch 79/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 7.5236 - mae: 8.0057 - val_loss: 17.8320 - val_mae: 18.3234\n",
      "Epoch 80/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 7.5625 - mae: 8.0447 - val_loss: 17.4550 - val_mae: 17.9457\n",
      "Epoch 81/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 7.4861 - mae: 7.9678 - val_loss: 17.7049 - val_mae: 18.1953\n",
      "Epoch 82/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 7.5639 - mae: 8.0464 - val_loss: 17.2557 - val_mae: 17.7465\n",
      "Epoch 83/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 7.4605 - mae: 7.9420 - val_loss: 17.3019 - val_mae: 17.7924\n",
      "Epoch 84/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 7.4861 - mae: 7.9676 - val_loss: 17.2685 - val_mae: 17.7595\n",
      "Epoch 85/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.4935 - mae: 7.9752 - val_loss: 17.4227 - val_mae: 17.9138\n",
      "Epoch 86/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 7.5014 - mae: 7.9832 - val_loss: 17.3967 - val_mae: 17.8876\n",
      "Epoch 87/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.4821 - mae: 7.9639 - val_loss: 17.2797 - val_mae: 17.7705\n",
      "Epoch 88/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 7.4690 - mae: 7.9506 - val_loss: 17.5369 - val_mae: 18.0279\n",
      "Epoch 89/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 7.5245 - mae: 8.0065 - val_loss: 17.2114 - val_mae: 17.7022\n",
      "Epoch 90/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.4620 - mae: 7.9436 - val_loss: 17.3142 - val_mae: 17.8047\n",
      "Epoch 91/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 7.4832 - mae: 7.9649 - val_loss: 17.2894 - val_mae: 17.7802\n",
      "Epoch 92/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.4773 - mae: 7.9591 - val_loss: 17.2043 - val_mae: 17.6951\n",
      "Epoch 93/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 7.4630 - mae: 7.9447 - val_loss: 17.1761 - val_mae: 17.6673\n",
      "Epoch 94/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.4768 - mae: 7.9588 - val_loss: 17.0530 - val_mae: 17.5439\n",
      "Epoch 95/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.4797 - mae: 7.9617 - val_loss: 17.2137 - val_mae: 17.7042\n",
      "Epoch 96/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 7.4761 - mae: 7.9580 - val_loss: 17.1048 - val_mae: 17.5952\n",
      "Epoch 97/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.4282 - mae: 7.9098 - val_loss: 16.8199 - val_mae: 17.3112\n",
      "Epoch 98/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 7.4600 - mae: 7.9421 - val_loss: 16.8246 - val_mae: 17.3156\n",
      "Epoch 99/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 7.4106 - mae: 7.8922 - val_loss: 16.8728 - val_mae: 17.3644\n",
      "Epoch 100/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 7.4445 - mae: 7.9265 - val_loss: 17.0870 - val_mae: 17.5778\n",
      "Epoch 101/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 7.4514 - mae: 7.9334 - val_loss: 16.9168 - val_mae: 17.4087\n",
      "Epoch 102/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 7.4669 - mae: 7.9490 - val_loss: 16.9637 - val_mae: 17.4550\n",
      "Epoch 103/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 7.4488 - mae: 7.9308 - val_loss: 16.8697 - val_mae: 17.3615\n",
      "Epoch 104/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 7.4452 - mae: 7.9273 - val_loss: 16.7915 - val_mae: 17.2827\n",
      "Epoch 105/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 7.4325 - mae: 7.9144 - val_loss: 16.6970 - val_mae: 17.1884\n",
      "Epoch 106/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 7.4064 - mae: 7.8882 - val_loss: 16.7272 - val_mae: 17.2185\n",
      "Epoch 107/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 7.4586 - mae: 7.9409 - val_loss: 16.9006 - val_mae: 17.3917\n",
      "Epoch 108/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.4316 - mae: 7.9138 - val_loss: 16.9144 - val_mae: 17.4058\n",
      "Epoch 109/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 7.4564 - mae: 7.9389 - val_loss: 16.7681 - val_mae: 17.2593\n",
      "Epoch 110/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 7.4274 - mae: 7.9094 - val_loss: 16.6644 - val_mae: 17.1559\n",
      "Epoch 111/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 7.3828 - mae: 7.8645 - val_loss: 16.6763 - val_mae: 17.1686\n",
      "Epoch 112/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 7.3986 - mae: 7.8807 - val_loss: 16.7504 - val_mae: 17.2412\n",
      "Epoch 113/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 7.3989 - mae: 7.8810 - val_loss: 16.4750 - val_mae: 16.9656\n",
      "Epoch 114/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.3896 - mae: 7.8713 - val_loss: 16.4743 - val_mae: 16.9642\n",
      "Epoch 115/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.3923 - mae: 7.8742 - val_loss: 16.3955 - val_mae: 16.8855\n",
      "Epoch 116/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.4065 - mae: 7.8885 - val_loss: 16.4076 - val_mae: 16.8980\n",
      "Epoch 117/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 7.3876 - mae: 7.8695 - val_loss: 16.5254 - val_mae: 17.0163\n",
      "Epoch 118/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 7.3881 - mae: 7.8702 - val_loss: 16.4921 - val_mae: 16.9808\n",
      "Epoch 119/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 7.4090 - mae: 7.8913 - val_loss: 16.4568 - val_mae: 16.9472\n",
      "Epoch 120/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 7.3824 - mae: 7.8645 - val_loss: 16.5205 - val_mae: 17.0115\n",
      "Epoch 121/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 7.4252 - mae: 7.9075 - val_loss: 16.6758 - val_mae: 17.1671\n",
      "Epoch 122/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 1s 28ms/step - loss: 7.4424 - mae: 7.9245 - val_loss: 16.3854 - val_mae: 16.8742\n",
      "Epoch 123/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.4172 - mae: 7.8994 - val_loss: 16.4231 - val_mae: 16.9130\n",
      "Epoch 124/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.4124 - mae: 7.8944 - val_loss: 16.3986 - val_mae: 16.8873\n",
      "Epoch 125/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.4166 - mae: 7.8987 - val_loss: 16.4268 - val_mae: 16.9171\n",
      "Epoch 126/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.3923 - mae: 7.8743 - val_loss: 16.4694 - val_mae: 16.9599\n",
      "Epoch 127/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.4112 - mae: 7.8934 - val_loss: 16.5437 - val_mae: 17.0347\n",
      "Epoch 128/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.4077 - mae: 7.8896 - val_loss: 17.9241 - val_mae: 18.4145\n",
      "Epoch 129/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 7.5061 - mae: 7.9878 - val_loss: 17.0578 - val_mae: 17.5498\n",
      "Epoch 130/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 7.4412 - mae: 7.9228 - val_loss: 17.0741 - val_mae: 17.5656\n",
      "Epoch 131/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 7.4797 - mae: 7.9617 - val_loss: 17.0433 - val_mae: 17.5334\n",
      "Epoch 132/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 7.4339 - mae: 7.9157 - val_loss: 17.0540 - val_mae: 17.5449\n",
      "Epoch 133/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 7.4303 - mae: 7.9118 - val_loss: 16.8995 - val_mae: 17.3901\n",
      "Epoch 134/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 7.4517 - mae: 7.9336 - val_loss: 17.0388 - val_mae: 17.5295\n",
      "Epoch 135/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 7.4374 - mae: 7.9193 - val_loss: 16.9185 - val_mae: 17.4095\n",
      "Epoch 136/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 7.4227 - mae: 7.9047 - val_loss: 16.9649 - val_mae: 17.4558\n",
      "Epoch 137/500\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 7.4812 - mae: 7.9631 - val_loss: 17.8231 - val_mae: 18.3135\n",
      "Epoch 138/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 7.4939 - mae: 7.9758 - val_loss: 17.5308 - val_mae: 18.0217\n",
      "Epoch 139/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 7.4729 - mae: 7.9543 - val_loss: 17.3249 - val_mae: 17.8163\n",
      "Epoch 140/500\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 7.4749 - mae: 7.9562 - val_loss: 17.3572 - val_mae: 17.8479\n",
      "Epoch 141/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 7.5030 - mae: 7.9847 - val_loss: 17.2900 - val_mae: 17.7804\n",
      "Epoch 142/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 7.4302 - mae: 7.9117 - val_loss: 17.3158 - val_mae: 17.8058\n",
      "Epoch 143/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.4470 - mae: 7.9282 - val_loss: 17.1354 - val_mae: 17.6260\n",
      "Epoch 144/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 7.4495 - mae: 7.9309 - val_loss: 17.4040 - val_mae: 17.8950\n",
      "Epoch 145/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 7.4423 - mae: 7.9239 - val_loss: 17.1728 - val_mae: 17.6630\n",
      "Epoch 146/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 7.4261 - mae: 7.9073 - val_loss: 17.3303 - val_mae: 17.8203\n",
      "Epoch 147/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.4392 - mae: 7.9208 - val_loss: 17.0666 - val_mae: 17.5567\n",
      "Epoch 148/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 7.4268 - mae: 7.9083 - val_loss: 16.9476 - val_mae: 17.4382\n",
      "Epoch 149/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.4221 - mae: 7.9039 - val_loss: 17.0095 - val_mae: 17.5006\n",
      "Epoch 150/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 7.4628 - mae: 7.9449 - val_loss: 17.1872 - val_mae: 17.6777\n",
      "Epoch 151/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 7.4469 - mae: 7.9287 - val_loss: 17.0753 - val_mae: 17.5662\n",
      "Epoch 152/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 7.4724 - mae: 7.9546 - val_loss: 16.9578 - val_mae: 17.4495\n",
      "Epoch 153/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 7.4343 - mae: 7.9163 - val_loss: 17.3215 - val_mae: 17.8129\n",
      "Epoch 154/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 7.4675 - mae: 7.9494 - val_loss: 16.6740 - val_mae: 17.1643\n",
      "Epoch 155/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 7.4040 - mae: 7.8854 - val_loss: 17.1607 - val_mae: 17.6520\n",
      "Epoch 156/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.4776 - mae: 7.9599 - val_loss: 17.0636 - val_mae: 17.5538\n",
      "Epoch 157/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.4386 - mae: 7.9204 - val_loss: 17.4046 - val_mae: 17.8971\n",
      "Epoch 158/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.4843 - mae: 7.9665 - val_loss: 16.9515 - val_mae: 17.4434\n",
      "Epoch 159/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 7.4431 - mae: 7.9250 - val_loss: 16.8896 - val_mae: 17.3813\n",
      "Epoch 160/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 7.4142 - mae: 7.8960 - val_loss: 17.0731 - val_mae: 17.5653\n",
      "Epoch 161/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 7.4278 - mae: 7.9099 - val_loss: 16.9098 - val_mae: 17.4019\n",
      "Epoch 162/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 7.3931 - mae: 7.8748 - val_loss: 16.9429 - val_mae: 17.4337\n",
      "Epoch 163/500\n",
      "36/36 [==============================] - 1s 35ms/step - loss: 7.4530 - mae: 7.9351 - val_loss: 16.5996 - val_mae: 17.0907\n",
      "Epoch 164/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 7.3605 - mae: 7.8418 - val_loss: 16.7164 - val_mae: 17.2063\n",
      "Epoch 165/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 7.4650 - mae: 7.9474 - val_loss: 16.8058 - val_mae: 17.2958\n",
      "Epoch 166/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 7.4375 - mae: 7.9194 - val_loss: 17.1756 - val_mae: 17.6680\n",
      "Epoch 167/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.4463 - mae: 7.9285 - val_loss: 16.7316 - val_mae: 17.2223\n",
      "Epoch 168/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 7.4201 - mae: 7.9023 - val_loss: 16.9062 - val_mae: 17.3976\n",
      "Epoch 169/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.4512 - mae: 7.9336 - val_loss: 16.9582 - val_mae: 17.4496\n",
      "Epoch 170/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 7.4324 - mae: 7.9146 - val_loss: 17.0073 - val_mae: 17.4989\n",
      "Epoch 171/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 7.4416 - mae: 7.9236 - val_loss: 16.7685 - val_mae: 17.2591\n",
      "Epoch 172/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 7.4179 - mae: 7.9001 - val_loss: 16.8416 - val_mae: 17.3326\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 16.3854 - mae: 16.8742\n",
      "LSTM Model Forecast MAE = 16874223.709106445\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "lstm_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.LSTM(32, return_sequences=True, input_shape=[None,1]),\n",
    "    tf.keras.layers.Dense(14)\n",
    "])\n",
    "\n",
    "lstm_mae = fit_and_evaluate(lstm_model, seq2seq_train, seq2seq_valid, learning_rate=0.01)\n",
    "print(f\"LSTM Model Forecast MAE = {lstm_mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08357e1b",
   "metadata": {},
   "source": [
    "#### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "80541c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "36/36 [==============================] - 4s 45ms/step - loss: 25.8399 - mae: 26.3399 - val_loss: 39.3916 - val_mae: 39.8916\n",
      "Epoch 2/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 19.3292 - mae: 19.8286 - val_loss: 31.9389 - val_mae: 32.4389\n",
      "Epoch 3/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 12.2524 - mae: 12.7423 - val_loss: 24.8845 - val_mae: 25.3825\n",
      "Epoch 4/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 8.7502 - mae: 9.2312 - val_loss: 21.3798 - val_mae: 21.8757\n",
      "Epoch 5/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 8.1181 - mae: 8.6029 - val_loss: 20.2829 - val_mae: 20.7811\n",
      "Epoch 6/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 8.0303 - mae: 8.5178 - val_loss: 19.9073 - val_mae: 20.4038\n",
      "Epoch 7/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.9985 - mae: 8.4855 - val_loss: 20.2756 - val_mae: 20.7735\n",
      "Epoch 8/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.9714 - mae: 8.4563 - val_loss: 20.4495 - val_mae: 20.9480\n",
      "Epoch 9/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 8.0550 - mae: 8.5374 - val_loss: 20.8805 - val_mae: 21.3792\n",
      "Epoch 10/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 8.0192 - mae: 8.5024 - val_loss: 19.9523 - val_mae: 20.4493\n",
      "Epoch 11/500\n",
      "36/36 [==============================] - 1s 35ms/step - loss: 7.9902 - mae: 8.4736 - val_loss: 20.3415 - val_mae: 20.8400\n",
      "Epoch 12/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 8.0186 - mae: 8.5038 - val_loss: 19.9840 - val_mae: 20.4817\n",
      "Epoch 13/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 8.0133 - mae: 8.4964 - val_loss: 20.8066 - val_mae: 21.3056\n",
      "Epoch 14/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 8.0605 - mae: 8.5458 - val_loss: 21.7485 - val_mae: 22.2440\n",
      "Epoch 15/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 8.1844 - mae: 8.6668 - val_loss: 20.6638 - val_mae: 21.1628\n",
      "Epoch 16/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 8.0580 - mae: 8.5443 - val_loss: 20.0084 - val_mae: 20.5052\n",
      "Epoch 17/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 8.0743 - mae: 8.5567 - val_loss: 21.1696 - val_mae: 21.6672\n",
      "Epoch 18/500\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 8.1027 - mae: 8.5878 - val_loss: 20.2324 - val_mae: 20.7303\n",
      "Epoch 19/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 8.1144 - mae: 8.5969 - val_loss: 21.3411 - val_mae: 21.8374\n",
      "Epoch 20/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 8.1175 - mae: 8.6021 - val_loss: 20.4203 - val_mae: 20.9191\n",
      "Epoch 21/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 8.0291 - mae: 8.5158 - val_loss: 19.8797 - val_mae: 20.3763\n",
      "Epoch 22/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 8.0259 - mae: 8.5126 - val_loss: 19.6570 - val_mae: 20.1534\n",
      "Epoch 23/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 8.0109 - mae: 8.4978 - val_loss: 19.6459 - val_mae: 20.1423\n",
      "Epoch 24/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 8.0092 - mae: 8.4962 - val_loss: 19.6743 - val_mae: 20.1707\n",
      "Epoch 25/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 8.0106 - mae: 8.4976 - val_loss: 19.6710 - val_mae: 20.1674\n",
      "Epoch 26/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 8.0076 - mae: 8.4947 - val_loss: 19.7110 - val_mae: 20.2075\n",
      "Epoch 27/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.9791 - mae: 8.4653 - val_loss: 20.4653 - val_mae: 20.9638\n",
      "Epoch 28/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 8.0364 - mae: 8.5221 - val_loss: 19.5605 - val_mae: 20.0563\n",
      "Epoch 29/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 8.0086 - mae: 8.4954 - val_loss: 19.6384 - val_mae: 20.1346\n",
      "Epoch 30/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 8.0113 - mae: 8.4980 - val_loss: 19.6245 - val_mae: 20.1206\n",
      "Epoch 31/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 8.0095 - mae: 8.4964 - val_loss: 19.6681 - val_mae: 20.1644\n",
      "Epoch 32/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 8.0109 - mae: 8.4976 - val_loss: 19.6755 - val_mae: 20.1719\n",
      "Epoch 33/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 8.0080 - mae: 8.4949 - val_loss: 19.6725 - val_mae: 20.1688\n",
      "Epoch 34/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 8.0118 - mae: 8.4988 - val_loss: 19.7023 - val_mae: 20.1987\n",
      "Epoch 35/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 8.0118 - mae: 8.4987 - val_loss: 19.6743 - val_mae: 20.1707\n",
      "Epoch 36/500\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 8.0109 - mae: 8.4977 - val_loss: 19.6586 - val_mae: 20.1549\n",
      "Epoch 37/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 8.0105 - mae: 8.4974 - val_loss: 19.6713 - val_mae: 20.1676\n",
      "Epoch 38/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 8.0113 - mae: 8.4980 - val_loss: 19.6350 - val_mae: 20.1312\n",
      "Epoch 39/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 8.0091 - mae: 8.4960 - val_loss: 19.6661 - val_mae: 20.1623\n",
      "Epoch 40/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 8.0113 - mae: 8.4981 - val_loss: 19.6604 - val_mae: 20.1567\n",
      "Epoch 41/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 8.0093 - mae: 8.4962 - val_loss: 19.6792 - val_mae: 20.1755\n",
      "Epoch 42/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 8.0125 - mae: 8.4992 - val_loss: 19.6341 - val_mae: 20.1301\n",
      "Epoch 43/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 8.0095 - mae: 8.4963 - val_loss: 19.6377 - val_mae: 20.1338\n",
      "Epoch 44/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 8.0107 - mae: 8.4976 - val_loss: 19.6789 - val_mae: 20.1751\n",
      "Epoch 45/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 8.0105 - mae: 8.4972 - val_loss: 19.6563 - val_mae: 20.1525\n",
      "Epoch 46/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 8.0076 - mae: 8.4945 - val_loss: 19.6823 - val_mae: 20.1786\n",
      "Epoch 47/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 8.0102 - mae: 8.4969 - val_loss: 19.6810 - val_mae: 20.1769\n",
      "Epoch 48/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 8.0129 - mae: 8.4998 - val_loss: 19.6885 - val_mae: 20.1849\n",
      "Epoch 49/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 8.0101 - mae: 8.4969 - val_loss: 19.6532 - val_mae: 20.1494\n",
      "Epoch 50/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 8.0103 - mae: 8.4969 - val_loss: 19.6506 - val_mae: 20.1465\n",
      "Epoch 51/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 8.0086 - mae: 8.4957 - val_loss: 19.6864 - val_mae: 20.1827\n",
      "Epoch 52/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 8.0069 - mae: 8.4939 - val_loss: 19.7017 - val_mae: 20.1982\n",
      "Epoch 53/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 7.9970 - mae: 8.4835 - val_loss: 19.6196 - val_mae: 20.1157\n",
      "Epoch 54/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 8.0724 - mae: 8.5557 - val_loss: 21.2429 - val_mae: 21.7399\n",
      "Epoch 55/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 8.1096 - mae: 8.5943 - val_loss: 20.2803 - val_mae: 20.7785\n",
      "Epoch 56/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 8.0258 - mae: 8.5130 - val_loss: 19.8988 - val_mae: 20.3955\n",
      "Epoch 57/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 8.0140 - mae: 8.5012 - val_loss: 19.6972 - val_mae: 20.1937\n",
      "Epoch 58/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 8.0029 - mae: 8.4899 - val_loss: 19.6771 - val_mae: 20.1733\n",
      "Epoch 59/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.9951 - mae: 8.4819 - val_loss: 19.5966 - val_mae: 20.0927\n",
      "Epoch 60/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 8.0005 - mae: 8.4872 - val_loss: 19.5825 - val_mae: 20.0785\n",
      "Epoch 61/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 8.0009 - mae: 8.4877 - val_loss: 19.6051 - val_mae: 20.1013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 7.9974 - mae: 8.4843 - val_loss: 19.6610 - val_mae: 20.1571\n",
      "Epoch 63/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 8.0018 - mae: 8.4888 - val_loss: 19.6246 - val_mae: 20.1208\n",
      "Epoch 64/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 7.9983 - mae: 8.4852 - val_loss: 19.6277 - val_mae: 20.1240\n",
      "Epoch 65/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.9980 - mae: 8.4849 - val_loss: 19.6316 - val_mae: 20.1278\n",
      "Epoch 66/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.9956 - mae: 8.4825 - val_loss: 19.6359 - val_mae: 20.1319\n",
      "Epoch 67/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.9872 - mae: 8.4733 - val_loss: 19.4298 - val_mae: 19.9248\n",
      "Epoch 68/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 7.9980 - mae: 8.4837 - val_loss: 19.6898 - val_mae: 20.1852\n",
      "Epoch 69/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 7.9963 - mae: 8.4826 - val_loss: 19.5183 - val_mae: 20.0138\n",
      "Epoch 70/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 7.9935 - mae: 8.4802 - val_loss: 19.5746 - val_mae: 20.0705\n",
      "Epoch 71/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 7.9990 - mae: 8.4854 - val_loss: 19.5898 - val_mae: 20.0858\n",
      "Epoch 72/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 7.9918 - mae: 8.4785 - val_loss: 19.5667 - val_mae: 20.0624\n",
      "Epoch 73/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 7.9908 - mae: 8.4777 - val_loss: 19.6776 - val_mae: 20.1735\n",
      "Epoch 74/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.9630 - mae: 8.4491 - val_loss: 20.1008 - val_mae: 20.5991\n",
      "Epoch 75/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 8.0143 - mae: 8.5003 - val_loss: 19.4629 - val_mae: 19.9579\n",
      "Epoch 76/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 7.9912 - mae: 8.4779 - val_loss: 19.5394 - val_mae: 20.0347\n",
      "Epoch 77/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.9909 - mae: 8.4778 - val_loss: 19.5430 - val_mae: 20.0387\n",
      "Epoch 78/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 7.9888 - mae: 8.4754 - val_loss: 19.5461 - val_mae: 20.0414\n",
      "Epoch 79/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 7.9902 - mae: 8.4772 - val_loss: 19.5830 - val_mae: 20.0790\n",
      "Epoch 80/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.9894 - mae: 8.4764 - val_loss: 19.5086 - val_mae: 20.0039\n",
      "Epoch 81/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.9887 - mae: 8.4755 - val_loss: 19.4809 - val_mae: 19.9763\n",
      "Epoch 82/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.9838 - mae: 8.4708 - val_loss: 19.5280 - val_mae: 20.0234\n",
      "Epoch 83/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 7.9902 - mae: 8.4768 - val_loss: 19.5432 - val_mae: 20.0390\n",
      "Epoch 84/500\n",
      "36/36 [==============================] - 1s 34ms/step - loss: 7.9854 - mae: 8.4725 - val_loss: 19.4938 - val_mae: 19.9892\n",
      "Epoch 85/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.9825 - mae: 8.4695 - val_loss: 19.4946 - val_mae: 19.9899\n",
      "Epoch 86/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 7.9831 - mae: 8.4700 - val_loss: 19.4903 - val_mae: 19.9853\n",
      "Epoch 87/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.9826 - mae: 8.4695 - val_loss: 19.4407 - val_mae: 19.9356\n",
      "Epoch 88/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.9767 - mae: 8.4637 - val_loss: 19.4987 - val_mae: 19.9936\n",
      "Epoch 89/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.9759 - mae: 8.4630 - val_loss: 19.5135 - val_mae: 20.0084\n",
      "Epoch 90/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 7.9835 - mae: 8.4706 - val_loss: 19.4740 - val_mae: 19.9692\n",
      "Epoch 91/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.9835 - mae: 8.4704 - val_loss: 19.4613 - val_mae: 19.9565\n",
      "Epoch 92/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 7.9781 - mae: 8.4650 - val_loss: 19.4495 - val_mae: 19.9445\n",
      "Epoch 93/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 7.9828 - mae: 8.4695 - val_loss: 19.4966 - val_mae: 19.9920\n",
      "Epoch 94/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.9803 - mae: 8.4674 - val_loss: 19.4415 - val_mae: 19.9366\n",
      "Epoch 95/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.9790 - mae: 8.4659 - val_loss: 19.4929 - val_mae: 19.9877\n",
      "Epoch 96/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.9763 - mae: 8.4632 - val_loss: 19.4155 - val_mae: 19.9104\n",
      "Epoch 97/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 7.9725 - mae: 8.4593 - val_loss: 19.5575 - val_mae: 20.0526\n",
      "Epoch 98/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 7.9834 - mae: 8.4701 - val_loss: 19.4253 - val_mae: 19.9203\n",
      "Epoch 99/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 7.9745 - mae: 8.4616 - val_loss: 19.3967 - val_mae: 19.8915\n",
      "Epoch 100/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 7.9708 - mae: 8.4580 - val_loss: 19.3834 - val_mae: 19.8784\n",
      "Epoch 101/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 7.9723 - mae: 8.4595 - val_loss: 19.3615 - val_mae: 19.8564\n",
      "Epoch 102/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 7.9707 - mae: 8.4577 - val_loss: 19.4107 - val_mae: 19.9057\n",
      "Epoch 103/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 7.9713 - mae: 8.4584 - val_loss: 19.4128 - val_mae: 19.9076\n",
      "Epoch 104/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 7.9701 - mae: 8.4571 - val_loss: 19.3523 - val_mae: 19.8472\n",
      "Epoch 105/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 7.9733 - mae: 8.4601 - val_loss: 19.4804 - val_mae: 19.9751\n",
      "Epoch 106/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 7.9727 - mae: 8.4597 - val_loss: 19.3577 - val_mae: 19.8527\n",
      "Epoch 107/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 7.9709 - mae: 8.4581 - val_loss: 19.4531 - val_mae: 19.9485\n",
      "Epoch 108/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.9796 - mae: 8.4666 - val_loss: 19.3564 - val_mae: 19.8514\n",
      "Epoch 109/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 7.9707 - mae: 8.4575 - val_loss: 19.2901 - val_mae: 19.7852\n",
      "Epoch 110/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 7.9636 - mae: 8.4509 - val_loss: 19.4054 - val_mae: 19.9005\n",
      "Epoch 111/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 7.9702 - mae: 8.4570 - val_loss: 19.3498 - val_mae: 19.8444\n",
      "Epoch 112/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 7.9644 - mae: 8.4514 - val_loss: 19.2985 - val_mae: 19.7935\n",
      "Epoch 113/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.9655 - mae: 8.4527 - val_loss: 19.4138 - val_mae: 19.9090\n",
      "Epoch 114/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 7.9677 - mae: 8.4548 - val_loss: 19.2752 - val_mae: 19.7702\n",
      "Epoch 115/500\n",
      "36/36 [==============================] - 1s 35ms/step - loss: 7.9619 - mae: 8.4491 - val_loss: 19.3641 - val_mae: 19.8587\n",
      "Epoch 116/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.9626 - mae: 8.4495 - val_loss: 19.3225 - val_mae: 19.8172\n",
      "Epoch 117/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.9669 - mae: 8.4537 - val_loss: 19.3467 - val_mae: 19.8414\n",
      "Epoch 118/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.9673 - mae: 8.4541 - val_loss: 19.2445 - val_mae: 19.7397\n",
      "Epoch 119/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 7.9606 - mae: 8.4478 - val_loss: 19.3743 - val_mae: 19.8692\n",
      "Epoch 120/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 7.9604 - mae: 8.4475 - val_loss: 19.3203 - val_mae: 19.8149\n",
      "Epoch 121/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 7.9621 - mae: 8.4492 - val_loss: 19.3081 - val_mae: 19.8027\n",
      "Epoch 122/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 1s 21ms/step - loss: 7.9645 - mae: 8.4510 - val_loss: 19.2880 - val_mae: 19.7827\n",
      "Epoch 123/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 7.9595 - mae: 8.4465 - val_loss: 19.3246 - val_mae: 19.8195\n",
      "Epoch 124/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 7.9641 - mae: 8.4509 - val_loss: 19.2845 - val_mae: 19.7791\n",
      "Epoch 125/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.9556 - mae: 8.4428 - val_loss: 19.2725 - val_mae: 19.7673\n",
      "Epoch 126/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.9623 - mae: 8.4492 - val_loss: 19.3230 - val_mae: 19.8175\n",
      "Epoch 127/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 7.9564 - mae: 8.4435 - val_loss: 19.2690 - val_mae: 19.7636\n",
      "Epoch 128/500\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 7.9525 - mae: 8.4393 - val_loss: 19.5656 - val_mae: 20.0607\n",
      "Epoch 129/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 7.9660 - mae: 8.4529 - val_loss: 19.3251 - val_mae: 19.8197\n",
      "Epoch 130/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 7.9610 - mae: 8.4474 - val_loss: 19.1238 - val_mae: 19.6186\n",
      "Epoch 131/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 7.9435 - mae: 8.4306 - val_loss: 19.3736 - val_mae: 19.8687\n",
      "Epoch 132/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.9561 - mae: 8.4428 - val_loss: 19.1248 - val_mae: 19.6197\n",
      "Epoch 133/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 7.9370 - mae: 8.4243 - val_loss: 19.3991 - val_mae: 19.8939\n",
      "Epoch 134/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.9571 - mae: 8.4437 - val_loss: 19.0897 - val_mae: 19.5846\n",
      "Epoch 135/500\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 7.9326 - mae: 8.4199 - val_loss: 19.3003 - val_mae: 19.7946\n",
      "Epoch 136/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 7.9471 - mae: 8.4337 - val_loss: 19.2449 - val_mae: 19.7395\n",
      "Epoch 137/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.9325 - mae: 8.4196 - val_loss: 19.1612 - val_mae: 19.6560\n",
      "Epoch 138/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 7.9508 - mae: 8.4377 - val_loss: 19.1816 - val_mae: 19.6761\n",
      "Epoch 139/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 7.9564 - mae: 8.4433 - val_loss: 19.4250 - val_mae: 19.9206\n",
      "Epoch 140/500\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 7.9564 - mae: 8.4419 - val_loss: 19.0274 - val_mae: 19.5222\n",
      "Epoch 141/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.9262 - mae: 8.4136 - val_loss: 19.2399 - val_mae: 19.7339\n",
      "Epoch 142/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.9529 - mae: 8.4399 - val_loss: 19.2528 - val_mae: 19.7468\n",
      "Epoch 143/500\n",
      "36/36 [==============================] - 1s 35ms/step - loss: 7.9496 - mae: 8.4361 - val_loss: 19.0278 - val_mae: 19.5225\n",
      "Epoch 144/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 7.9306 - mae: 8.4179 - val_loss: 19.4455 - val_mae: 19.9410\n",
      "Epoch 145/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 7.9572 - mae: 8.4431 - val_loss: 19.0055 - val_mae: 19.5002\n",
      "Epoch 146/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 7.9219 - mae: 8.4091 - val_loss: 19.1958 - val_mae: 19.6901\n",
      "Epoch 147/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 7.9443 - mae: 8.4310 - val_loss: 19.1466 - val_mae: 19.6410\n",
      "Epoch 148/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 7.9488 - mae: 8.4356 - val_loss: 19.0900 - val_mae: 19.5847\n",
      "Epoch 149/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 7.9400 - mae: 8.4270 - val_loss: 19.2092 - val_mae: 19.7030\n",
      "Epoch 150/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 7.9441 - mae: 8.4305 - val_loss: 18.9515 - val_mae: 19.4459\n",
      "Epoch 151/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.9184 - mae: 8.4055 - val_loss: 19.0820 - val_mae: 19.5766\n",
      "Epoch 152/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 7.9382 - mae: 8.4254 - val_loss: 19.2796 - val_mae: 19.7740\n",
      "Epoch 153/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 7.9447 - mae: 8.4309 - val_loss: 18.9594 - val_mae: 19.4538\n",
      "Epoch 154/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.9179 - mae: 8.4051 - val_loss: 19.1205 - val_mae: 19.6148\n",
      "Epoch 155/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 7.9360 - mae: 8.4225 - val_loss: 19.0023 - val_mae: 19.4968\n",
      "Epoch 156/500\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 7.9195 - mae: 8.4065 - val_loss: 19.3278 - val_mae: 19.8225\n",
      "Epoch 157/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 7.9480 - mae: 8.4332 - val_loss: 18.9319 - val_mae: 19.4261\n",
      "Epoch 158/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.9114 - mae: 8.3984 - val_loss: 19.2072 - val_mae: 19.7008\n",
      "Epoch 159/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 7.9370 - mae: 8.4235 - val_loss: 19.0422 - val_mae: 19.5364\n",
      "Epoch 160/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 7.9320 - mae: 8.4187 - val_loss: 19.0551 - val_mae: 19.5491\n",
      "Epoch 161/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 7.9415 - mae: 8.4280 - val_loss: 19.1094 - val_mae: 19.6030\n",
      "Epoch 162/500\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 7.9302 - mae: 8.4160 - val_loss: 18.9164 - val_mae: 19.4106\n",
      "Epoch 163/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 7.9076 - mae: 8.3947 - val_loss: 19.2133 - val_mae: 19.7068\n",
      "Epoch 164/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 7.9287 - mae: 8.4142 - val_loss: 18.9467 - val_mae: 19.4409\n",
      "Epoch 165/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.9089 - mae: 8.3955 - val_loss: 18.9563 - val_mae: 19.4507\n",
      "Epoch 166/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 7.9183 - mae: 8.4052 - val_loss: 19.1981 - val_mae: 19.6914\n",
      "Epoch 167/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.9334 - mae: 8.4195 - val_loss: 18.8970 - val_mae: 19.3910\n",
      "Epoch 168/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 7.9076 - mae: 8.3946 - val_loss: 19.3356 - val_mae: 19.8304\n",
      "Epoch 169/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.9476 - mae: 8.4332 - val_loss: 18.8379 - val_mae: 19.3316\n",
      "Epoch 170/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 7.8975 - mae: 8.3841 - val_loss: 18.9001 - val_mae: 19.3941\n",
      "Epoch 171/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 7.9052 - mae: 8.3921 - val_loss: 19.2586 - val_mae: 19.7525\n",
      "Epoch 172/500\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 7.9373 - mae: 8.4226 - val_loss: 18.8817 - val_mae: 19.3755\n",
      "Epoch 173/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 7.9020 - mae: 8.3888 - val_loss: 18.9933 - val_mae: 19.4874\n",
      "Epoch 174/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 7.9229 - mae: 8.4093 - val_loss: 19.0692 - val_mae: 19.5627\n",
      "Epoch 175/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 7.9208 - mae: 8.4065 - val_loss: 18.8391 - val_mae: 19.3327\n",
      "Epoch 176/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 7.9027 - mae: 8.3896 - val_loss: 19.1423 - val_mae: 19.6346\n",
      "Epoch 177/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 7.9333 - mae: 8.4185 - val_loss: 18.8324 - val_mae: 19.3259\n",
      "Epoch 178/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 7.8956 - mae: 8.3819 - val_loss: 19.0307 - val_mae: 19.5239\n",
      "Epoch 179/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 7.9248 - mae: 8.4106 - val_loss: 18.7913 - val_mae: 19.2848\n",
      "Epoch 180/500\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 7.8947 - mae: 8.3812 - val_loss: 19.1057 - val_mae: 19.5981\n",
      "Epoch 181/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 7.9312 - mae: 8.4168 - val_loss: 19.2800 - val_mae: 19.7744\n",
      "Epoch 182/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 1s 22ms/step - loss: 7.9084 - mae: 8.3950 - val_loss: 19.1487 - val_mae: 19.6414\n",
      "Epoch 183/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.9303 - mae: 8.4154 - val_loss: 18.7975 - val_mae: 19.2912\n",
      "Epoch 184/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.8929 - mae: 8.3791 - val_loss: 18.9209 - val_mae: 19.4147\n",
      "Epoch 185/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 7.9117 - mae: 8.3976 - val_loss: 18.8964 - val_mae: 19.3900\n",
      "Epoch 186/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 7.9003 - mae: 8.3861 - val_loss: 18.8725 - val_mae: 19.3660\n",
      "Epoch 187/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 7.8904 - mae: 8.3764 - val_loss: 19.7100 - val_mae: 20.2062\n",
      "Epoch 188/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 7.9460 - mae: 8.4316 - val_loss: 18.8059 - val_mae: 19.2993\n",
      "Epoch 189/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.9080 - mae: 8.3942 - val_loss: 18.8745 - val_mae: 19.3679\n",
      "Epoch 190/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.9182 - mae: 8.4033 - val_loss: 18.7736 - val_mae: 19.2670\n",
      "Epoch 191/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 7.9133 - mae: 8.3998 - val_loss: 19.2648 - val_mae: 19.7593\n",
      "Epoch 192/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.9408 - mae: 8.4257 - val_loss: 18.6388 - val_mae: 19.1317\n",
      "Epoch 193/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 7.8846 - mae: 8.3709 - val_loss: 18.9377 - val_mae: 19.4315\n",
      "Epoch 194/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 7.9083 - mae: 8.3943 - val_loss: 18.9922 - val_mae: 19.4852\n",
      "Epoch 195/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 7.9164 - mae: 8.4018 - val_loss: 18.7584 - val_mae: 19.2518\n",
      "Epoch 196/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 7.8924 - mae: 8.3784 - val_loss: 18.7986 - val_mae: 19.2921\n",
      "Epoch 197/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.9056 - mae: 8.3915 - val_loss: 18.8846 - val_mae: 19.3779\n",
      "Epoch 198/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 7.9131 - mae: 8.3983 - val_loss: 19.1062 - val_mae: 19.6006\n",
      "Epoch 199/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 7.9140 - mae: 8.3993 - val_loss: 18.7287 - val_mae: 19.2220\n",
      "Epoch 200/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 7.8931 - mae: 8.3789 - val_loss: 18.9269 - val_mae: 19.4203\n",
      "Epoch 201/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 7.9199 - mae: 8.4051 - val_loss: 18.6772 - val_mae: 19.1703\n",
      "Epoch 202/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.8868 - mae: 8.3724 - val_loss: 18.8159 - val_mae: 19.3094\n",
      "Epoch 203/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 7.8983 - mae: 8.3831 - val_loss: 18.7851 - val_mae: 19.2787\n",
      "Epoch 204/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.8855 - mae: 8.3715 - val_loss: 18.8167 - val_mae: 19.3098\n",
      "Epoch 205/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 7.9123 - mae: 8.3975 - val_loss: 18.6977 - val_mae: 19.1910\n",
      "Epoch 206/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 7.8917 - mae: 8.3774 - val_loss: 18.8542 - val_mae: 19.3472\n",
      "Epoch 207/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 7.9190 - mae: 8.4041 - val_loss: 18.7119 - val_mae: 19.2051\n",
      "Epoch 208/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 7.8988 - mae: 8.3846 - val_loss: 18.9200 - val_mae: 19.4128\n",
      "Epoch 209/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.9198 - mae: 8.4045 - val_loss: 18.6646 - val_mae: 19.1577\n",
      "Epoch 210/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 7.8904 - mae: 8.3757 - val_loss: 18.7204 - val_mae: 19.2137\n",
      "Epoch 211/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.8915 - mae: 8.3767 - val_loss: 18.7219 - val_mae: 19.2152\n",
      "Epoch 212/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.8813 - mae: 8.3665 - val_loss: 18.7669 - val_mae: 19.2603\n",
      "Epoch 213/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 7.9015 - mae: 8.3865 - val_loss: 18.7289 - val_mae: 19.2223\n",
      "Epoch 214/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 7.8848 - mae: 8.3701 - val_loss: 18.7103 - val_mae: 19.2036\n",
      "Epoch 215/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.8915 - mae: 8.3765 - val_loss: 18.7000 - val_mae: 19.1933\n",
      "Epoch 216/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 7.8792 - mae: 8.3640 - val_loss: 18.7205 - val_mae: 19.2138\n",
      "Epoch 217/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 7.8840 - mae: 8.3694 - val_loss: 18.7823 - val_mae: 19.2755\n",
      "Epoch 218/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.9073 - mae: 8.3915 - val_loss: 18.6688 - val_mae: 19.1620\n",
      "Epoch 219/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.8799 - mae: 8.3655 - val_loss: 18.7707 - val_mae: 19.2636\n",
      "Epoch 220/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 7.9055 - mae: 8.3900 - val_loss: 18.6445 - val_mae: 19.1375\n",
      "Epoch 221/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.8837 - mae: 8.3688 - val_loss: 18.6458 - val_mae: 19.1387\n",
      "Epoch 222/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.8870 - mae: 8.3720 - val_loss: 18.6379 - val_mae: 19.1308\n",
      "Epoch 223/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.8764 - mae: 8.3608 - val_loss: 18.6123 - val_mae: 19.1051\n",
      "Epoch 224/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.8728 - mae: 8.3576 - val_loss: 18.6147 - val_mae: 19.1076\n",
      "Epoch 225/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 7.8746 - mae: 8.3595 - val_loss: 18.7993 - val_mae: 19.2923\n",
      "Epoch 226/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 7.8999 - mae: 8.3839 - val_loss: 18.6382 - val_mae: 19.1312\n",
      "Epoch 227/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.8706 - mae: 8.3554 - val_loss: 18.6352 - val_mae: 19.1282\n",
      "Epoch 228/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.8748 - mae: 8.3594 - val_loss: 18.7275 - val_mae: 19.2208\n",
      "Epoch 229/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 7.8796 - mae: 8.3644 - val_loss: 18.6315 - val_mae: 19.1245\n",
      "Epoch 230/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.8879 - mae: 8.3727 - val_loss: 18.6166 - val_mae: 19.1095\n",
      "Epoch 231/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 7.8784 - mae: 8.3625 - val_loss: 18.6250 - val_mae: 19.1179\n",
      "Epoch 232/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 7.8719 - mae: 8.3565 - val_loss: 18.6014 - val_mae: 19.0943\n",
      "Epoch 233/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 7.8681 - mae: 8.3534 - val_loss: 18.8232 - val_mae: 19.3158\n",
      "Epoch 234/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 7.9111 - mae: 8.3952 - val_loss: 18.6782 - val_mae: 19.1714\n",
      "Epoch 235/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 7.8758 - mae: 8.3607 - val_loss: 18.5459 - val_mae: 19.0384\n",
      "Epoch 236/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 7.8662 - mae: 8.3506 - val_loss: 18.6173 - val_mae: 19.1102\n",
      "Epoch 237/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.8773 - mae: 8.3617 - val_loss: 18.5999 - val_mae: 19.0928\n",
      "Epoch 238/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 7.8877 - mae: 8.3719 - val_loss: 18.5989 - val_mae: 19.0917\n",
      "Epoch 239/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.8875 - mae: 8.3716 - val_loss: 18.5603 - val_mae: 19.0530\n",
      "Epoch 240/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 7.8774 - mae: 8.3622 - val_loss: 18.7471 - val_mae: 19.2396\n",
      "Epoch 241/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.8985 - mae: 8.3823 - val_loss: 18.5053 - val_mae: 18.9976\n",
      "Epoch 242/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 1s 25ms/step - loss: 7.8704 - mae: 8.3550 - val_loss: 18.5566 - val_mae: 19.0492\n",
      "Epoch 243/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 7.8789 - mae: 8.3640 - val_loss: 18.9869 - val_mae: 19.4784\n",
      "Epoch 244/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 7.9165 - mae: 8.4007 - val_loss: 18.6389 - val_mae: 19.1316\n",
      "Epoch 245/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 7.8594 - mae: 8.3442 - val_loss: 18.5461 - val_mae: 19.0387\n",
      "Epoch 246/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 7.8900 - mae: 8.3745 - val_loss: 18.7124 - val_mae: 19.2051\n",
      "Epoch 247/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 7.9091 - mae: 8.3928 - val_loss: 18.8541 - val_mae: 19.3484\n",
      "Epoch 248/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 7.8728 - mae: 8.3573 - val_loss: 18.5295 - val_mae: 19.0220\n",
      "Epoch 249/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 7.8770 - mae: 8.3617 - val_loss: 18.5871 - val_mae: 19.0796\n",
      "Epoch 250/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 7.8895 - mae: 8.3732 - val_loss: 18.4948 - val_mae: 18.9870\n",
      "Epoch 251/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 7.8673 - mae: 8.3511 - val_loss: 18.5554 - val_mae: 19.0480\n",
      "Epoch 252/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.8712 - mae: 8.3558 - val_loss: 18.5145 - val_mae: 19.0068\n",
      "Epoch 253/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.8783 - mae: 8.3626 - val_loss: 18.5628 - val_mae: 19.0554\n",
      "Epoch 254/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.8889 - mae: 8.3732 - val_loss: 18.5545 - val_mae: 19.0470\n",
      "Epoch 255/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 7.8881 - mae: 8.3716 - val_loss: 18.5104 - val_mae: 19.0028\n",
      "Epoch 256/500\n",
      "36/36 [==============================] - 1s 34ms/step - loss: 7.8641 - mae: 8.3483 - val_loss: 18.5196 - val_mae: 19.0120\n",
      "Epoch 257/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 7.8695 - mae: 8.3533 - val_loss: 18.5349 - val_mae: 19.0273\n",
      "Epoch 258/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.8705 - mae: 8.3545 - val_loss: 18.4954 - val_mae: 18.9876\n",
      "Epoch 259/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 7.8762 - mae: 8.3602 - val_loss: 18.5888 - val_mae: 19.0816\n",
      "Epoch 260/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 7.8801 - mae: 8.3635 - val_loss: 18.4606 - val_mae: 18.9526\n",
      "Epoch 261/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.8633 - mae: 8.3471 - val_loss: 18.4780 - val_mae: 18.9701\n",
      "Epoch 262/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 7.8641 - mae: 8.3481 - val_loss: 18.5190 - val_mae: 19.0114\n",
      "Epoch 263/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 7.8712 - mae: 8.3546 - val_loss: 18.4843 - val_mae: 18.9764\n",
      "Epoch 264/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.8604 - mae: 8.3444 - val_loss: 18.5828 - val_mae: 19.0756\n",
      "Epoch 265/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.8685 - mae: 8.3526 - val_loss: 18.5090 - val_mae: 19.0012\n",
      "Epoch 266/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 7.8709 - mae: 8.3547 - val_loss: 18.4177 - val_mae: 18.9094\n",
      "Epoch 267/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.8682 - mae: 8.3518 - val_loss: 18.5182 - val_mae: 19.0106\n",
      "Epoch 268/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 7.8712 - mae: 8.3555 - val_loss: 18.4736 - val_mae: 18.9655\n",
      "Epoch 269/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 7.8914 - mae: 8.3748 - val_loss: 18.4120 - val_mae: 18.9037\n",
      "Epoch 270/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 7.8637 - mae: 8.3474 - val_loss: 18.4378 - val_mae: 18.9296\n",
      "Epoch 271/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.8655 - mae: 8.3495 - val_loss: 18.4209 - val_mae: 18.9126\n",
      "Epoch 272/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 7.8623 - mae: 8.3459 - val_loss: 18.4536 - val_mae: 18.9455\n",
      "Epoch 273/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.8685 - mae: 8.3524 - val_loss: 18.5138 - val_mae: 19.0063\n",
      "Epoch 274/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.8995 - mae: 8.3830 - val_loss: 19.3194 - val_mae: 19.8151\n",
      "Epoch 275/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.8910 - mae: 8.3772 - val_loss: 18.9411 - val_mae: 19.4347\n",
      "Epoch 276/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.9306 - mae: 8.4155 - val_loss: 18.0942 - val_mae: 18.5860\n",
      "Epoch 277/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.8759 - mae: 8.3607 - val_loss: 18.3151 - val_mae: 18.8067\n",
      "Epoch 278/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 7.8872 - mae: 8.3707 - val_loss: 18.3455 - val_mae: 18.8369\n",
      "Epoch 279/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.8554 - mae: 8.3392 - val_loss: 18.3688 - val_mae: 18.8603\n",
      "Epoch 280/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.8658 - mae: 8.3492 - val_loss: 18.4507 - val_mae: 18.9426\n",
      "Epoch 281/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.8596 - mae: 8.3427 - val_loss: 18.4124 - val_mae: 18.9041\n",
      "Epoch 282/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.8485 - mae: 8.3322 - val_loss: 18.4370 - val_mae: 18.9288\n",
      "Epoch 283/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 7.8699 - mae: 8.3533 - val_loss: 18.4282 - val_mae: 18.9200\n",
      "Epoch 284/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.8651 - mae: 8.3485 - val_loss: 18.5567 - val_mae: 19.0494\n",
      "Epoch 285/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 7.8705 - mae: 8.3539 - val_loss: 18.4259 - val_mae: 18.9177\n",
      "Epoch 286/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 7.8763 - mae: 8.3593 - val_loss: 18.4003 - val_mae: 18.8919\n",
      "Epoch 287/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 7.8551 - mae: 8.3385 - val_loss: 18.3750 - val_mae: 18.8666\n",
      "Epoch 288/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 7.8613 - mae: 8.3444 - val_loss: 18.5853 - val_mae: 19.0780\n",
      "Epoch 289/500\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 7.8538 - mae: 8.3375 - val_loss: 18.3680 - val_mae: 18.8595\n",
      "Epoch 290/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 7.8613 - mae: 8.3445 - val_loss: 18.3702 - val_mae: 18.8617\n",
      "Epoch 291/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 7.8481 - mae: 8.3317 - val_loss: 18.3803 - val_mae: 18.8719\n",
      "Epoch 292/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 7.8672 - mae: 8.3503 - val_loss: 18.6421 - val_mae: 19.1353\n",
      "Epoch 293/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 7.8722 - mae: 8.3554 - val_loss: 18.3525 - val_mae: 18.8439\n",
      "Epoch 294/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 7.8599 - mae: 8.3427 - val_loss: 18.3780 - val_mae: 18.8695\n",
      "Epoch 295/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 7.8432 - mae: 8.3268 - val_loss: 18.3531 - val_mae: 18.8445\n",
      "Epoch 296/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.8747 - mae: 8.3582 - val_loss: 19.2240 - val_mae: 19.7188\n",
      "Epoch 297/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.8995 - mae: 8.3855 - val_loss: 18.4622 - val_mae: 18.9539\n",
      "Epoch 298/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 7.8999 - mae: 8.3838 - val_loss: 18.1882 - val_mae: 18.6796\n",
      "Epoch 299/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 7.8443 - mae: 8.3286 - val_loss: 18.3030 - val_mae: 18.7945\n",
      "Epoch 300/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.8732 - mae: 8.3560 - val_loss: 18.3140 - val_mae: 18.8054\n",
      "Epoch 301/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.8474 - mae: 8.3308 - val_loss: 18.3295 - val_mae: 18.8208\n",
      "Epoch 302/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 1s 26ms/step - loss: 7.8604 - mae: 8.3437 - val_loss: 18.3245 - val_mae: 18.8158\n",
      "Epoch 303/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.8304 - mae: 8.3126 - val_loss: 19.3475 - val_mae: 19.8430\n",
      "Epoch 304/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 7.8628 - mae: 8.3475 - val_loss: 18.4564 - val_mae: 18.9479\n",
      "Epoch 305/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 7.8858 - mae: 8.3690 - val_loss: 18.2673 - val_mae: 18.7587\n",
      "Epoch 306/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 7.8536 - mae: 8.3368 - val_loss: 18.2702 - val_mae: 18.7615\n",
      "Epoch 307/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.8502 - mae: 8.3337 - val_loss: 18.2780 - val_mae: 18.7694\n",
      "Epoch 308/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 7.8543 - mae: 8.3375 - val_loss: 18.2636 - val_mae: 18.7550\n",
      "Epoch 309/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.8537 - mae: 8.3366 - val_loss: 18.3236 - val_mae: 18.8152\n",
      "Epoch 310/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 7.8514 - mae: 8.3343 - val_loss: 18.3426 - val_mae: 18.8339\n",
      "Epoch 311/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.8444 - mae: 8.3272 - val_loss: 18.3233 - val_mae: 18.8146\n",
      "Epoch 312/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 7.8522 - mae: 8.3353 - val_loss: 18.3182 - val_mae: 18.8095\n",
      "Epoch 313/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 7.8667 - mae: 8.3494 - val_loss: 18.2234 - val_mae: 18.7148\n",
      "Epoch 314/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.8358 - mae: 8.3187 - val_loss: 18.2852 - val_mae: 18.7765\n",
      "Epoch 315/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 7.8467 - mae: 8.3300 - val_loss: 18.2785 - val_mae: 18.7699\n",
      "Epoch 316/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.8574 - mae: 8.3398 - val_loss: 18.2936 - val_mae: 18.7849\n",
      "Epoch 317/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 7.8666 - mae: 8.3495 - val_loss: 18.3602 - val_mae: 18.8522\n",
      "Epoch 318/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 7.8361 - mae: 8.3199 - val_loss: 18.2847 - val_mae: 18.7768\n",
      "Epoch 319/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.8734 - mae: 8.3565 - val_loss: 18.2140 - val_mae: 18.7054\n",
      "Epoch 320/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 7.8502 - mae: 8.3331 - val_loss: 18.3032 - val_mae: 18.7948\n",
      "Epoch 321/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 7.8386 - mae: 8.3221 - val_loss: 18.2567 - val_mae: 18.7482\n",
      "Epoch 322/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 7.8681 - mae: 8.3510 - val_loss: 18.2788 - val_mae: 18.7701\n",
      "Epoch 323/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 7.8723 - mae: 8.3547 - val_loss: 18.2907 - val_mae: 18.7820\n",
      "Epoch 324/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 7.8650 - mae: 8.3478 - val_loss: 18.2869 - val_mae: 18.7783\n",
      "Epoch 325/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 7.8728 - mae: 8.3554 - val_loss: 18.2817 - val_mae: 18.7730\n",
      "Epoch 326/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 7.8628 - mae: 8.3459 - val_loss: 18.2565 - val_mae: 18.7480\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 18.0942 - mae: 18.5860\n",
      "GRP Model Forecast MAE = 18585975.646972656\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "gru_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.GRU(32, return_sequences=True, input_shape=[None, 1]),\n",
    "    tf.keras.layers.Dense(14)\n",
    "])\n",
    "\n",
    "gru_mae = fit_and_evaluate(gru_model, seq2seq_train, seq2seq_valid, learning_rate=0.01)\n",
    "print(f\"GRU Model Forecast MAE = {gru_mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d060e552",
   "metadata": {},
   "source": [
    "#### Using 1D Convolutional Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ad20b4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "conv_rnn_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv1D(filters=32, kernel_size=4, strides=2, activation=\"relu\", input_shape=[None,1]),\n",
    "    tf.keras.layers.GRU(32, return_sequences=True),\n",
    "    tf.keras.layers.Dense(14)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b6e70eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "longer_train = to_seq2seq_dataset(volume_train, seq_length=112, shuffle=True, seed=42)\n",
    "longer_valid = to_seq2seq_dataset(volume_valid, seq_length=112)\n",
    "downsampled_train = longer_train.map(lambda X, Y: (X, Y[:, 3::2]))\n",
    "downsampled_valid = longer_valid.map(lambda X, Y: (X, Y[:, 3::2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e1619c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "34/34 [==============================] - 5s 53ms/step - loss: 16.0453 - mae: 16.5385 - val_loss: 16.4107 - val_mae: 16.8987\n",
      "Epoch 2/500\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 8.3084 - mae: 8.7952 - val_loss: 21.0014 - val_mae: 21.5007\n",
      "Epoch 3/500\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 8.1615 - mae: 8.6473 - val_loss: 20.3543 - val_mae: 20.8515\n",
      "Epoch 4/500\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 8.1287 - mae: 8.6154 - val_loss: 20.3737 - val_mae: 20.8711\n",
      "Epoch 5/500\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 8.1329 - mae: 8.6198 - val_loss: 20.3972 - val_mae: 20.8948\n",
      "Epoch 6/500\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 8.1263 - mae: 8.6132 - val_loss: 20.3933 - val_mae: 20.8908\n",
      "Epoch 7/500\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 8.1272 - mae: 8.6142 - val_loss: 20.2945 - val_mae: 20.7915\n",
      "Epoch 8/500\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 8.1553 - mae: 8.6406 - val_loss: 20.4802 - val_mae: 20.9783\n",
      "Epoch 9/500\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 8.1548 - mae: 8.6412 - val_loss: 20.5351 - val_mae: 21.0334\n",
      "Epoch 10/500\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 8.1315 - mae: 8.6182 - val_loss: 20.3466 - val_mae: 20.8438\n",
      "Epoch 11/500\n",
      "34/34 [==============================] - 1s 32ms/step - loss: 8.1217 - mae: 8.6084 - val_loss: 20.3526 - val_mae: 20.8498\n",
      "Epoch 12/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 8.1199 - mae: 8.6061 - val_loss: 20.4258 - val_mae: 20.9235\n",
      "Epoch 13/500\n",
      "34/34 [==============================] - 1s 32ms/step - loss: 8.1212 - mae: 8.6080 - val_loss: 20.3012 - val_mae: 20.7981\n",
      "Epoch 14/500\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 8.1150 - mae: 8.6018 - val_loss: 20.4198 - val_mae: 20.9175\n",
      "Epoch 15/500\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 8.1211 - mae: 8.6079 - val_loss: 20.3145 - val_mae: 20.8115\n",
      "Epoch 16/500\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 8.1224 - mae: 8.6088 - val_loss: 20.4770 - val_mae: 20.9750\n",
      "Epoch 17/500\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 8.1297 - mae: 8.6158 - val_loss: 20.4497 - val_mae: 20.9476\n",
      "Epoch 18/500\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 8.1188 - mae: 8.6059 - val_loss: 20.2499 - val_mae: 20.7467\n",
      "Epoch 19/500\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 8.1190 - mae: 8.6052 - val_loss: 20.5504 - val_mae: 21.0488\n",
      "Epoch 20/500\n",
      "34/34 [==============================] - 1s 33ms/step - loss: 8.1345 - mae: 8.6208 - val_loss: 20.4263 - val_mae: 20.9241\n",
      "Epoch 21/500\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 8.1242 - mae: 8.6108 - val_loss: 20.3141 - val_mae: 20.8112\n",
      "Epoch 22/500\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 8.1243 - mae: 8.6108 - val_loss: 20.4015 - val_mae: 20.8991\n",
      "Epoch 23/500\n",
      "34/34 [==============================] - 1s 32ms/step - loss: 8.1215 - mae: 8.6085 - val_loss: 20.2896 - val_mae: 20.7865\n",
      "Epoch 24/500\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 8.1241 - mae: 8.6106 - val_loss: 20.4549 - val_mae: 20.9528\n",
      "Epoch 25/500\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 8.1195 - mae: 8.6062 - val_loss: 20.3064 - val_mae: 20.8034\n",
      "Epoch 26/500\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 8.1172 - mae: 8.6042 - val_loss: 20.4401 - val_mae: 20.9379\n",
      "Epoch 27/500\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 8.1435 - mae: 8.6302 - val_loss: 20.3507 - val_mae: 20.8479\n",
      "Epoch 28/500\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 8.1377 - mae: 8.6242 - val_loss: 20.3859 - val_mae: 20.8833\n",
      "Epoch 29/500\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 8.1173 - mae: 8.6037 - val_loss: 20.3921 - val_mae: 20.8896\n",
      "Epoch 30/500\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 8.1371 - mae: 8.6235 - val_loss: 20.4715 - val_mae: 20.9695\n",
      "Epoch 31/500\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 8.1357 - mae: 8.6220 - val_loss: 20.5654 - val_mae: 21.0639\n",
      "Epoch 32/500\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 8.1265 - mae: 8.6125 - val_loss: 20.4716 - val_mae: 20.9696\n",
      "Epoch 33/500\n",
      "34/34 [==============================] - 1s 32ms/step - loss: 8.1292 - mae: 8.6154 - val_loss: 20.4671 - val_mae: 20.9651\n",
      "Epoch 34/500\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 8.1202 - mae: 8.6067 - val_loss: 20.4447 - val_mae: 20.9425\n",
      "Epoch 35/500\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 8.1215 - mae: 8.6086 - val_loss: 20.1989 - val_mae: 20.6955\n",
      "Epoch 36/500\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 8.1199 - mae: 8.6067 - val_loss: 20.4339 - val_mae: 20.9317\n",
      "Epoch 37/500\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 8.1286 - mae: 8.6148 - val_loss: 20.4373 - val_mae: 20.9351\n",
      "Epoch 38/500\n",
      "34/34 [==============================] - 1s 33ms/step - loss: 8.1315 - mae: 8.6177 - val_loss: 20.4980 - val_mae: 20.9962\n",
      "Epoch 39/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 8.1336 - mae: 8.6200 - val_loss: 20.4376 - val_mae: 20.9354\n",
      "Epoch 40/500\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 8.1330 - mae: 8.6195 - val_loss: 20.3805 - val_mae: 20.8779\n",
      "Epoch 41/500\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 8.1249 - mae: 8.6118 - val_loss: 20.3113 - val_mae: 20.8083\n",
      "Epoch 42/500\n",
      "34/34 [==============================] - 1s 33ms/step - loss: 8.1298 - mae: 8.6160 - val_loss: 20.5965 - val_mae: 21.0951\n",
      "Epoch 43/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 8.1365 - mae: 8.6224 - val_loss: 20.5145 - val_mae: 21.0128\n",
      "Epoch 44/500\n",
      "34/34 [==============================] - 1s 33ms/step - loss: 8.1351 - mae: 8.6217 - val_loss: 20.3946 - val_mae: 20.8921\n",
      "Epoch 45/500\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 8.1300 - mae: 8.6166 - val_loss: 20.4083 - val_mae: 20.9059\n",
      "Epoch 46/500\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 8.1354 - mae: 8.6221 - val_loss: 20.3310 - val_mae: 20.8281\n",
      "Epoch 47/500\n",
      "34/34 [==============================] - 1s 32ms/step - loss: 8.1297 - mae: 8.6159 - val_loss: 20.5616 - val_mae: 21.0601\n",
      "Epoch 48/500\n",
      "34/34 [==============================] - 1s 32ms/step - loss: 8.1271 - mae: 8.6139 - val_loss: 20.3169 - val_mae: 20.8140\n",
      "Epoch 49/500\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 8.1089 - mae: 8.5957 - val_loss: 20.3667 - val_mae: 20.8640\n",
      "Epoch 50/500\n",
      "34/34 [==============================] - 1s 33ms/step - loss: 8.1116 - mae: 8.5981 - val_loss: 20.3827 - val_mae: 20.8801\n",
      "Epoch 51/500\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 8.1204 - mae: 8.6070 - val_loss: 20.4169 - val_mae: 20.9147\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 16.4107 - mae: 16.8987\n",
      "1D Convolutional Layers Model Forecast MAE = 16898727.416992188\n"
     ]
    }
   ],
   "source": [
    "oned_conv_mae = fit_and_evaluate(conv_rnn_model, downsampled_train, downsampled_valid, learning_rate=0.1)\n",
    "print(f\"1D Convolutional Layers Model Forecast MAE = {oned_conv_mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35cb9e8",
   "metadata": {},
   "source": [
    "#### Compare Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1e02d7fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 900x650 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "models = ['Naive', 'SARIMA', 'Simple RNN', 'Deep RNN', 'Seq2Seq', 'LN RNN', 'LSTM', 'GRU', '1D Conv']\n",
    "mae_values = [naive_mae, sarima_mae, simple_rnn_mae, deep_rnn_mae, seq2seq_mae, ln_rnn_mae, lstm_mae, gru_mae, oned_conv_mae]\n",
    "mean_mae = np.mean(mae_values)\n",
    "\n",
    "mae_values = np.array(mae_values) / 100_000\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(9, 6.5))\n",
    "plt.scatter(models, mae_values, color='blue', s=20, label='MAE values')\n",
    "plt.axhline(y=mean_mae / 100_000, color='r', linestyle='--', label=f'Mean MAE: {mean_mae:.2f}')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Mean Absolute Error (MAE)')\n",
    "plt.title('Comparison of MAE for Different Forecasting Models')\n",
    "plt.xticks(rotation=60, ha='right')\n",
    "\n",
    "for model, mae in zip(models, mae_values):\n",
    "    plt.text(model, mae + 5, round(mae, 2), ha='center', va='bottom') \n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
